{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14927063,"datasetId":9551535,"databundleVersionId":15794187},{"sourceType":"datasetVersion","sourceId":101413,"datasetId":53291,"databundleVersionId":103953},{"sourceType":"datasetVersion","sourceId":4588404,"datasetId":2675000,"databundleVersionId":4649793},{"sourceType":"kernelVersion","sourceId":299970533,"isSourceIdPinned":false}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9595e3ad","cell_type":"code","source":"!pip install -q noisereduce pyloudnorm soundfile librosa transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:55:33.317250Z","iopub.execute_input":"2026-02-25T08:55:33.317599Z","iopub.status.idle":"2026-02-25T08:55:37.756744Z","shell.execute_reply.started":"2026-02-25T08:55:33.317564Z","shell.execute_reply":"2026-02-25T08:55:37.755418Z"}},"outputs":[],"execution_count":2},{"id":"f06df653-775d-405b-82e9-996732efb8af","cell_type":"markdown","source":"### Wipe Kaggle's Output Storage","metadata":{}},{"id":"2184223c-ebcf-4d96-a569-e0a08aa1ea13","cell_type":"code","source":"import os\nimport shutil\n\nworking_dir = '/kaggle/working'\n\nprint(\"ğŸŸ¡ Wiping Kaggle working directory...\")\n\nfor item in os.listdir(working_dir):\n    item_path = os.path.join(working_dir, item)\n    try:\n        if os.path.isfile(item_path) or os.path.islink(item_path):\n            os.unlink(item_path)\n        elif os.path.isdir(item_path):\n            shutil.rmtree(item_path)\n    except Exception as e:\n        print(f\"ğŸ”´ Failed to delete {item_path}. Reason: {e}\")\n\nprint(\"ğŸŸ¢ Kaggle working directory is completely clean.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:23:16.169823Z","iopub.execute_input":"2026-02-25T08:23:16.170165Z","iopub.status.idle":"2026-02-25T08:23:16.179636Z","shell.execute_reply.started":"2026-02-25T08:23:16.170133Z","shell.execute_reply":"2026-02-25T08:23:16.178412Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¡ Wiping Kaggle working directory...\nğŸŸ¢ Kaggle working directory is completely clean.\n","output_type":"stream"}],"execution_count":2},{"id":"3a4d9a93-0729-4381-92e6-21f1101d510b","cell_type":"markdown","source":"### Remove a Specific Folder/File","metadata":{}},{"id":"79622b28-b88f-47e0-a74a-d5e635002071","cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\ndef delete_target(target_path):\n    target = Path(target_path)\n    \n    if not target.exists():\n        print(f\"ğŸŸ¡ Target does not exist: {target}\")\n        return\n        \n    try:\n        if target.is_file() or target.is_symlink():\n            target.unlink()\n            print(f\"ğŸŸ¢ Successfully deleted file: {target}\")\n        elif target.is_dir():\n            shutil.rmtree(target)\n            print(f\"ğŸŸ¢ Successfully deleted directory: {target}\")\n    except Exception as e:\n        print(f\"ğŸ”´ Failed to delete {target}. Reason: {e}\")\n\n# Just drop your path here\ndelete_target('/kaggle/working/clap_cache.npz')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:30:49.181583Z","iopub.execute_input":"2026-02-25T08:30:49.182019Z","iopub.status.idle":"2026-02-25T08:30:49.191230Z","shell.execute_reply.started":"2026-02-25T08:30:49.181988Z","shell.execute_reply":"2026-02-25T08:30:49.189910Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ Successfully deleted file: /kaggle/working/clap_cache.npz\n","output_type":"stream"}],"execution_count":13},{"id":"34b748e3","cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 0 â€” Environment & Path Configuration\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nimport os, json, hashlib, time, random, warnings, shutil, pickle\nfrom pathlib import Path\nfrom typing import Optional, List, Dict, Tuple\nfrom collections import defaultdict\n\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom scipy.signal import fftconvolve\nimport noisereduce as nr\n\nwarnings.filterwarnings('ignore')\nrandom.seed(42)\nnp.random.seed(42)\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# KAGGLE INPUT PATHS  (datasets attached to this notebook)\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPATHS = {\n    'irs':       Path('/kaggle/input/datasets/itorousa/impulse-responses'),\n    'mit_raw':   Path('/kaggle/input/notebooks/itorousa/genesis-data-run1/irs/mit_irs/Audio'),\n    'ljspeech':  Path('/kaggle/input/datasets/dromosys/ljspeech/'),\n    'vctk':      Path('/kaggle/input/datasets/kynthesis/vctk-corpus/VCTK-Corpus/wav48'),\n#   'langid_en': Path('/kaggle/input/datasets/shrivatssudhir/language-identifier/english/clips'),\n}\n\n# Chaining â€” previous run's output (attached as input to this notebook).\n# Adjust the path for each subsequent run.\nPREV_RUN_PATH = Path('/kaggle/input/notebooks/itorousa/genesis-data-run1')\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# OUTPUT\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT          = Path('/kaggle/working')\nBATCH_DIR       = OUTPUT / 'batches'\nCLAP_DIR        = OUTPUT / 'clap_model'\nSTERILIZED_DIR  = OUTPUT / 'sterilized_batches'\nMIT_IR_DIR      = OUTPUT / 'irs' / 'mit_irs'\n\nfor d in [BATCH_DIR, CLAP_DIR, STERILIZED_DIR, MIT_IR_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# AUDIO PARAMETERS\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSR            = 48_000\nCLIP_SEC      = 5.0\nCLIP_SAMPLES  = int(SR * CLIP_SEC)    # 240,000 samples\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# BUDGET & BATCHING\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nTRIPLES_PER_BATCH  = 500\nMAX_OUTPUT_GB      = 19.0             # safety margin under 20 GB cap\nAUGMENTATIONS_MIN  = 3\nAUGMENTATIONS_MAX  = 6\n\nprint(f\"SR={SR}, CLIP_SEC={CLIP_SEC}, CLIP_SAMPLES={CLIP_SAMPLES}\")\nprint(f\"Output budget: {MAX_OUTPUT_GB} GB, batch size: {TRIPLES_PER_BATCH}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:55:48.092774Z","iopub.execute_input":"2026-02-25T08:55:48.093177Z","iopub.status.idle":"2026-02-25T08:55:52.992778Z","shell.execute_reply.started":"2026-02-25T08:55:48.093137Z","shell.execute_reply":"2026-02-25T08:55:52.991308Z"}},"outputs":[{"name":"stdout","text":"SR=48000, CLIP_SEC=5.0, CLIP_SAMPLES=240000\nOutput budget: 19.0 GB, batch size: 500\n","output_type":"stream"}],"execution_count":3},{"id":"ab6336cd","cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 1 â€” Aggressive Checkpoint Initialization & Hardware Protection\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCHECKPOINT_PATH = OUTPUT / 'checkpoint.json'\n\ndef load_checkpoint() -> dict:\n    '''Load checkpoint: previous run â†’ current working dir â†’ fresh start.'''\n    # 1) Check previous run first (chaining)\n    prev_ckpt = PREV_RUN_PATH / 'checkpoint.json'\n    if prev_ckpt.exists():\n        with open(prev_ckpt) as f:\n            ckpt = json.load(f)\n        ckpt['run_number'] += 1\n        print(f\"[Checkpoint] â™» Resuming from previous run: \"\n              f\"{ckpt['triples_completed']} triples done\")\n        return ckpt\n\n    # 2) Check current working dir (kernel restart mid-session)\n    if CHECKPOINT_PATH.exists():\n        with open(CHECKPOINT_PATH) as f:\n            return json.load(f)\n\n    # 3) Fresh start\n    return {\n        'batch_id': 0,\n        'triples_completed': 0,\n        'vocal_cursor': 0,\n        'run_number': 1,\n    }\n\ndef save_checkpoint(ckpt: dict):\n    with open(CHECKPOINT_PATH, 'w') as f:\n        json.dump(ckpt, f, indent=2)\n\ndef get_output_size_gb() -> float:\n    '''Calculate the exact size of /kaggle/working in GB.'''\n    total = sum(f.stat().st_size for f in OUTPUT.rglob('*') if f.is_file())\n    return total / (1024 ** 3)\n\nckpt = load_checkpoint()\n\nsave_checkpoint(ckpt) # <-- Added this line to initialize the file immediately ğŸ’¾\n\nprint(f\"[Checkpoint] Run #{ckpt['run_number']}, \"\n      f\"{ckpt['triples_completed']} triples completed so far, \"\n      f\"starting at vocal cursor {ckpt['vocal_cursor']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:55:58.052755Z","iopub.execute_input":"2026-02-25T08:55:58.053253Z","iopub.status.idle":"2026-02-25T08:55:58.071278Z","shell.execute_reply.started":"2026-02-25T08:55:58.053223Z","shell.execute_reply":"2026-02-25T08:55:58.069878Z"}},"outputs":[{"name":"stdout","text":"[Checkpoint] â™» Resuming from previous run: 0 triples done\n[Checkpoint] Run #2, 0 triples completed so far, starting at vocal cursor 0\n","output_type":"stream"}],"execution_count":4},{"id":"85eb9eb0","cell_type":"code","source":"import urllib.request\nimport zipfile\nimport shutil\nimport json\nimport librosa\nimport numpy as np\nfrom typing import Dict, List, Optional\nfrom pathlib import Path\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 2 â€” Impulse Response Acquisition & Pooling\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCATALOGUE_PATH = OUTPUT / 'ir_catalogue.json'\nMIT_RAW_URL = 'https://mcdermottlab.mit.edu/Reverb/IRMAudio/Audio.zip'\n\n# â”€â”€â”€ Fast path: reload from existing catalogue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nif CATALOGUE_PATH.exists():\n    print(\"ğŸŸ¢ Found existing ir_catalogue.json â€” skipping audio-loading block.\")\n    with open(CATALOGUE_PATH, 'r') as f:\n        ir_catalogue = json.load(f)\n\n    all_irs: Dict[str, dict] = {}   # will NOT have audio yet; lazy-loaded later\n    bad_pool:    List[str] = []\n    target_pool: List[str] = []\n\n    for ir_id, feats in ir_catalogue.items():\n        if feats['source'] == 'mit':\n            target_pool.append(ir_id)\n        elif feats['rt60'] > 0.25 or feats['c50'] < 8:\n            bad_pool.append(ir_id)\n        else:\n            bad_pool.append(ir_id)\n\n    # Safety: ensure target pool is adequate\n    if len(target_pool) < 20:\n        mit_ids = [k for k, v in ir_catalogue.items() if v['source'] == 'mit']\n        target_pool = mit_ids if mit_ids else list(ir_catalogue.keys())[:50]\n        bad_pool = [k for k in ir_catalogue if k not in target_pool]\n\n    print(f\"ğŸŸ¢ Loaded {len(ir_catalogue)} IRs from catalogue\")\n    print(f\"ğŸŸ¢ Bad pool: {len(bad_pool)} | Target pool: {len(target_pool)}\")\n    _catalogue_loaded_from_disk = True\n\nelse:\n    _catalogue_loaded_from_disk = False\n\n    # â”€â”€â”€ Stage 1: Copy / acquire MIT IRs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    prev_mit = PREV_RUN_PATH / 'irs' / 'mit_irs'\n    MIT_IR_DIR.mkdir(parents=True, exist_ok=True)\n    \n    if prev_mit.exists() and not any(MIT_IR_DIR.iterdir()):\n        print(\"ğŸŸ¢ [Acquire] Copying MIT IRs from previous run...\")\n        shutil.copytree(prev_mit, MIT_IR_DIR, dirs_exist_ok=True)\n        print(\"ğŸŸ¢ [Acquire] MIT IRs staged from previous run âœ“\")\n    elif not any(MIT_IR_DIR.iterdir()):\n        print(\"ğŸŸ¢ [Acquire] Downloading MIT IRs...\")\n        zip_path = MIT_IR_DIR / 'mit_irs.zip'\n        urllib.request.urlretrieve(MIT_RAW_URL, str(zip_path))\n        with zipfile.ZipFile(zip_path, 'r') as zf:\n            zf.extractall(MIT_IR_DIR)\n        zip_path.unlink()\n        print(\"ğŸŸ¢ [Acquire] MIT IRs downloaded and extracted âœ“\")\n    else:\n        print(\"ğŸŸ¢ [Acquire] MIT IRs already staged or unavailable\")\n\n    # â”€â”€â”€ Stage 2: Load & normalize every IR to 48 kHz mono â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def load_and_normalize_ir(filepath: Path, target_sr: int = SR) -> Optional[np.ndarray]:\n        '''Load an IR file, force mono / target SR, peak-normalize.'''\n        try:\n            audio, _ = librosa.load(str(filepath), sr=target_sr, mono=True)\n            if len(audio) < 64:\n                return None\n            peak = np.max(np.abs(audio))\n            if peak > 1e-6:\n                audio = audio / peak\n            return audio.astype(np.float32)\n        except Exception:\n            return None\n\n    print(\"\\nğŸŸ¢ [Acquire] Loading all impulse responses...\")\n    all_irs: Dict[str, dict] = {}\n\n    # Target pool â€” my IRs\n    for ext in ('*.irs', '*.wav'):\n        for f in sorted(PATHS['irs'].rglob(ext)):\n            ir = load_and_normalize_ir(f)\n            if ir is not None:\n                all_irs[f'user_{f.stem}'] = {'audio': ir, 'source': 'user'}\n\n    # Bad pool â€” MIT IRs\n    if MIT_IR_DIR.exists():\n        for f in sorted(MIT_IR_DIR.rglob('*.wav')):\n            ir = load_and_normalize_ir(f)\n            if ir is not None:\n                all_irs[f'mit_{f.stem}'] = {'audio': ir, 'source': 'mit'}\n\n    print(f\"ğŸŸ¢ [Acquire] Loaded {len(all_irs)} IRs \"\n          f\"(user/target: {sum(1 for v in all_irs.values() if v['source']=='user')}, \"\n          f\"MIT/bad: {sum(1 for v in all_irs.values() if v['source']=='mit')})\")\n\n    # â”€â”€â”€ Stage 3: Classify & build pools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def compute_ir_features(ir_audio: np.ndarray, sr: int = SR) -> dict:\n        '''Compute RT60 estimate, spectral centroid, and clarity (C50).'''\n        energy = ir_audio ** 2\n        cumsum = np.cumsum(energy[::-1])[::-1]\n\n        # RT60 â€” time for energy to decay 60 dB\n        rt60 = len(ir_audio) / sr\n        if cumsum[0] > 1e-10:\n            decay_db = 10 * np.log10(cumsum / cumsum[0] + 1e-12)\n            idx = np.where(decay_db < -60)[0]\n            if len(idx) > 0:\n                rt60 = idx[0] / sr\n\n        # Spectral centroid\n        S = np.abs(np.fft.rfft(ir_audio))\n        freqs = np.fft.rfftfreq(len(ir_audio), 1 / sr)\n        centroid = float(np.sum(freqs * S) / (np.sum(S) + 1e-10))\n\n        # Clarity C50 â€” early-to-late energy ratio at 50 ms\n        split = int(0.05 * sr)\n        early = np.sum(ir_audio[:split] ** 2) + 1e-12\n        late  = np.sum(ir_audio[split:] ** 2) + 1e-12\n        c50   = float(10 * np.log10(early / late))\n\n        return {\n            'rt60': round(rt60, 4),\n            'centroid': round(centroid, 1),\n            'c50': round(c50, 2),\n            'length_sec': round(len(ir_audio) / sr, 4),\n        }\n\n    ir_catalogue = {}\n    bad_pool:    List[str] = []\n    target_pool: List[str] = []\n\n    for ir_id, ir_data in all_irs.items():\n        feats = compute_ir_features(ir_data['audio'])\n        ir_data['features'] = feats\n        ir_catalogue[ir_id] = {'source': ir_data['source'], **feats}\n\n        # MIT IRs â†’ bad pool\n        # User IRs â†’ target pool\n        if ir_data['source'] == 'user':\n            target_pool.append(ir_id)\n        else:\n            bad_pool.append(ir_id)\n\n    # Safety: ensure target pool is adequate\n    if len(target_pool) < 20:\n        user_ids = sorted(\n            [k for k, v in all_irs.items() if v['source'] == 'user'],\n            key=lambda k: all_irs[k]['features']['c50'], reverse=True\n        )\n        target_pool = user_ids if user_ids else list(all_irs.keys())[:50]\n        bad_pool = [k for k in all_irs if k not in target_pool]\n\n    print(f\"ğŸŸ¢ [Classify] Bad pool:    {len(bad_pool)} IRs\")\n    print(f\"ğŸŸ¢ [Classify] Target pool: {len(target_pool)} IRs\")\n\n    # ğŸ’¾ Save catalogue\n    with open(CATALOGUE_PATH, 'w') as f:\n        json.dump(ir_catalogue, f, indent=2)\n    print(\"ğŸŸ¢ [Classify] ir_catalogue.json saved âœ“\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:56:03.017411Z","iopub.execute_input":"2026-02-25T08:56:03.017793Z","iopub.status.idle":"2026-02-25T08:56:24.821453Z","shell.execute_reply.started":"2026-02-25T08:56:03.017761Z","shell.execute_reply":"2026-02-25T08:56:24.819917Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [Acquire] Copying MIT IRs from previous run...\nğŸŸ¢ [Acquire] MIT IRs staged from previous run âœ“\n\nğŸŸ¢ [Acquire] Loading all impulse responses...\nğŸŸ¢ [Acquire] Loaded 659 IRs (user/target: 389, MIT/bad: 270)\nğŸŸ¢ [Classify] Bad pool:    270 IRs\nğŸŸ¢ [Classify] Target pool: 389 IRs\nğŸŸ¢ [Classify] ir_catalogue.json saved âœ“\n","output_type":"stream"}],"execution_count":5},{"id":"8fc6437b","cell_type":"code","source":"import torch\nfrom transformers import ClapModel, ClapProcessor\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 3 â€” CLAP Target Embedding Cache\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCLAP_MODEL_ID = \"laion/larger_clap_music_and_speech\"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"ğŸŸ¢ [CLAP] Device: {device}\")\n\n# â”€â”€â”€ Model loading chain: local â†’ previous run â†’ download â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprev_clap = PREV_RUN_PATH / 'clap_model'\n\nif (CLAP_DIR / 'config.json').exists():\n    print(\"ğŸŸ¢ [CLAP] Loading frozen model from current working dir...\")\n    clap_processor = ClapProcessor.from_pretrained(CLAP_DIR)\n    clap_model = ClapModel.from_pretrained(CLAP_DIR).to(device).eval()\n\nelif prev_clap.exists() and (prev_clap / 'config.json').exists():\n    print(\"ğŸŸ¢ [CLAP] Copying frozen model from previous run...\")\n    shutil.copytree(prev_clap, CLAP_DIR, dirs_exist_ok=True)\n    clap_processor = ClapProcessor.from_pretrained(CLAP_DIR)\n    clap_model = ClapModel.from_pretrained(CLAP_DIR).to(device).eval()\n\nelse:\n    print(\"ğŸŸ¢ [CLAP] Downloading model from Hugging Face...\")\n    clap_processor = ClapProcessor.from_pretrained(CLAP_MODEL_ID)\n    clap_model = ClapModel.from_pretrained(CLAP_MODEL_ID).to(device).eval()\n    clap_model.save_pretrained(CLAP_DIR)\n    clap_processor.save_pretrained(CLAP_DIR)\n    print(f\"ğŸŸ¢ [CLAP] Frozen model saved to {CLAP_DIR}\")\n\nCLAP_DIM = clap_model.config.projection_dim\nprint(f\"ğŸŸ¢ [CLAP] Loaded â€” embedding dim = {CLAP_DIM}\")\n\n\ndef get_clap_audio_embedding(audio: np.ndarray, sr: int = SR) -> np.ndarray:\n    '''\n    Encode audio through CLAP's audio tower. Returns (CLAP_DIM,) float32.\n\n    âš  Critical: extract .pooler_output from the wrapper before calling .cpu().\n    '''\n    inputs = clap_processor(\n        audio=audio, sampling_rate=sr, return_tensors=\"pt\"\n    )\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    with torch.no_grad():\n        outputs = clap_model.get_audio_features(**inputs)\n        emb = outputs.pooler_output\n    return emb.cpu().numpy().flatten().astype(np.float32)\n\n\n# â”€â”€â”€ Pre-compute CLAP embeddings for every target-pool IR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Convolve each IR with 3s of white noise so CLAP has a rich scene.\nCLAP_CACHE_PATH = OUTPUT / 'clap_cache.npz'\nprev_cache = PREV_RUN_PATH / 'clap_cache.npz'\n\nif CLAP_CACHE_PATH.exists():\n    print(\"ğŸŸ¢ [CLAP] Found existing clap_cache.npz â€” skipping embedding compute.\")\n    clap_cache = dict(np.load(CLAP_CACHE_PATH))\n    print(f\"ğŸŸ¢ [CLAP] Loaded {len(clap_cache)} embeddings from cache âœ“  (dim={CLAP_DIM})\")\n\nelif prev_cache.exists():\n    print(\"ğŸŸ¢ [CLAP] Copying clap_cache.npz from previous run...\")\n    shutil.copy2(prev_cache, CLAP_CACHE_PATH)\n    clap_cache = dict(np.load(CLAP_CACHE_PATH))\n    print(f\"ğŸŸ¢ [CLAP] Loaded {len(clap_cache)} embeddings from previous run âœ“\")\n\nelse:\n    print(f\"\\nğŸŸ¢ [CLAP] Pre-computing embeddings for {len(target_pool)} target IRs...\")\n\n    # Need IR audio loaded â€” if catalogue was loaded from disk, lazy-load now\n    if _catalogue_loaded_from_disk:\n        print(\"   (Lazy-loading IR audio for embedding computation...)\")\n        def _lazy_load_ir(ir_id: str) -> Optional[np.ndarray]:\n            if ir_id.startswith('mit_'):\n                for f in MIT_IR_DIR.rglob('*.wav'):\n                    if f.stem == ir_id[4:]:\n                        audio, _ = librosa.load(str(f), sr=SR, mono=True)\n                        peak = np.max(np.abs(audio))\n                        return (audio / peak).astype(np.float32) if peak > 1e-6 else audio\n            elif ir_id.startswith('user_'):\n                for ext in ('*.irs', '*.wav'):\n                    for f in PATHS['irs'].rglob(ext):\n                        if f.stem == ir_id[5:]:\n                            audio, _ = librosa.load(str(f), sr=SR, mono=True)\n                            peak = np.max(np.abs(audio))\n                            return (audio / peak).astype(np.float32) if peak > 1e-6 else audio\n            return None\n\n        all_irs = {}\n        for ir_id in target_pool + bad_pool:\n            a = _lazy_load_ir(ir_id)\n            if a is not None:\n                all_irs[ir_id] = {'audio': a, 'source': ir_catalogue[ir_id]['source']}\n\n    ref_noise = np.random.randn(SR * 3).astype(np.float32) * 0.1\n\n    clap_cache: Dict[str, np.ndarray] = {}\n    for i, ir_id in enumerate(target_pool):\n        if ir_id not in all_irs:\n            continue\n        ir_audio = all_irs[ir_id]['audio']\n        scene = fftconvolve(ref_noise, ir_audio, mode='full')[:SR * 3]\n        scene = scene / (np.max(np.abs(scene)) + 1e-8)\n        clap_cache[ir_id] = get_clap_audio_embedding(scene)\n        if (i + 1) % 50 == 0:\n            print(f\"  {i+1}/{len(target_pool)}\")\n\n    np.savez(CLAP_CACHE_PATH, **clap_cache)\n    print(f\"ğŸŸ¢ [CLAP] Cached {len(clap_cache)} embeddings âœ“  (dim={CLAP_DIM})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:56:42.153189Z","iopub.execute_input":"2026-02-25T08:56:42.153556Z","iopub.status.idle":"2026-02-25T08:57:12.556115Z","shell.execute_reply.started":"2026-02-25T08:56:42.153527Z","shell.execute_reply":"2026-02-25T08:57:12.554897Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [CLAP] Device: cpu\nğŸŸ¢ [CLAP] Copying frozen model from previous run...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/555 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8902ffa4b2c649008ca943df20b30862"}},"metadata":{}},{"name":"stdout","text":"ğŸŸ¢ [CLAP] Loaded â€” embedding dim = 512\nğŸŸ¢ [CLAP] Copying clap_cache.npz from previous run...\nğŸŸ¢ [CLAP] Loaded 389 embeddings from previous run âœ“\n","output_type":"stream"}],"execution_count":6},{"id":"1542e8be","cell_type":"code","source":"import pyloudnorm as pyln\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 4 â€” Vocal Sterilization & \"Dead\" Audio Guarantee\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nmeter = pyln.Meter(SR)\nSTATE_FILE = STERILIZED_DIR / 'sterilize_state.json'\n\n# â”€â”€â”€ Check if a previous run already completed sterilization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprev_sterilized = PREV_RUN_PATH / 'sterilized_batches'\nprev_state_file = prev_sterilized / 'sterilize_state.json' if prev_sterilized.exists() else None\n\n_skip_sterilization = False\nif prev_state_file and prev_state_file.exists():\n    with open(prev_state_file) as f:\n        prev_state = json.load(f)\n    if prev_state.get('completed', False):\n        print(\"ğŸŸ¢ [Sterilize] Previous run completed sterilization. Copying batches...\")\n        shutil.copytree(prev_sterilized, STERILIZED_DIR, dirs_exist_ok=True)\n        _skip_sterilization = True\n        print(\"ğŸŸ¢ [Sterilize] Sterilized batches copied from previous run âœ“\")\n\nif STATE_FILE.exists() and not _skip_sterilization:\n    with open(STATE_FILE) as f:\n        _st = json.load(f)\n    if _st.get('completed', False):\n        print(\"ğŸŸ¢ [Sterilize] Already completed in this working dir. Skipping.\")\n        _skip_sterilization = True\n\nif not _skip_sterilization:\n    def discover_audio_files() -> List[Tuple[Path, str]]:\n        '''Collect all vocal files from all datasets.'''\n        files = []\n        # LJSpeech\n        for f in sorted(PATHS['ljspeech'].rglob('*.wav')):\n            files.append((f, 'ljspeech'))\n        # VCTK â€” subfolder per speaker\n        for f in sorted(PATHS['vctk'].rglob('*.wav')):\n            files.append((f, f'vctk_{f.parent.name}'))\n        # Language Identifier â€” english clips\n        for ext in ('*.wav', '*.mp3', '*.ogg'):\n            for f in sorted(PATHS['langid_en'].rglob(ext)):\n                files.append((f, 'langid_en'))\n        return files\n\n    def sterilize_and_segment(filepath: Path, tag: str) -> List[dict]:\n        '''Load â†’ noise-reduce â†’ trim â†’ LUFS normalize â†’ segment into 5s windows.'''\n        try:\n            audio, _ = librosa.load(str(filepath), sr=SR, mono=True)\n        except Exception:\n            return []\n\n        if len(audio) < SR * 1.0:\n            return []\n\n        # Spectral noise reduction â€” strip residual room tone / hiss\n        audio = nr.reduce_noise(y=audio, sr=SR, stationary=True, prop_decrease=0.85)\n\n        # Trim absolute silence\n        audio, _ = librosa.effects.trim(audio, top_db=40)\n        if len(audio) < SR * 1.5:\n            return []\n\n        # Normalize loudness to -23 LUFS\n        try:\n            loudness = meter.integrated_loudness(audio)\n            if loudness > -70:\n                audio = pyln.normalize.loudness(audio, loudness, -23.0)\n        except Exception:\n            pass\n\n        # Segment into rigid CLIP_SAMPLES (5.0s) chunks\n        segments = []\n        for start in range(0, len(audio) - SR, CLIP_SAMPLES):\n            chunk = audio[start : start + CLIP_SAMPLES]\n            if len(chunk) < CLIP_SAMPLES:\n                chunk = np.pad(chunk, (0, CLIP_SAMPLES - len(chunk)))\n\n            rms = np.sqrt(np.mean(chunk ** 2))\n            if rms < 1e-4:\n                continue\n\n            segments.append({\n                'audio':   chunk.astype(np.float32),\n                'file':    filepath.name,\n                'dataset': tag,\n            })\n        return segments\n\n    # â”€â”€ Discover & deterministic shuffle â”€â”€\n    print(\"ğŸŸ¢ [Sterilize] Discovering audio files...\")\n    all_audio_files = discover_audio_files()\n\n    # Sort alphabetically â†’ shuffle with fixed seed for reproducibility\n    all_audio_files.sort(key=lambda x: str(x[0]))\n    random.Random(42).shuffle(all_audio_files)\n    print(f\"ğŸŸ¢ [Sterilize] Found {len(all_audio_files)} source files\")\n\n    # â”€â”€ Resume from sterilize checkpoint â”€â”€\n    cursor_start = 0\n    if STATE_FILE.exists():\n        with open(STATE_FILE) as f:\n            cursor_start = json.load(f).get('cursor', 0)\n\n    STERILIZE_CHUNK = 500\n    vocal_segments: List[dict] = []\n\n    print(f\"ğŸŸ¢ [Sterilize] Processing from file index {cursor_start}...\")\n    for i in range(cursor_start, len(all_audio_files)):\n        fpath, tag = all_audio_files[i]\n\n        # Budget check\n        if get_output_size_gb() > MAX_OUTPUT_GB:\n            print(f\"\\nâš  Output size limit reached. Saving sterilization progress.\")\n            break\n\n        if i % 200 == 0 and i > cursor_start:\n            print(f\"ğŸŸ¢ Processed {i}/{len(all_audio_files)} files â†’ \"\n                  f\"{len(vocal_segments)} segments in RAM buffer\")\n\n        segs = sterilize_and_segment(fpath, tag)\n        vocal_segments.extend(segs)\n\n        # ğŸ’¾ Granular disk flushing every STERILIZE_CHUNK files\n        if (i + 1) % STERILIZE_CHUNK == 0 or (i + 1) == len(all_audio_files):\n            batch_index = (i + 1) // STERILIZE_CHUNK\n            batch_path = STERILIZED_DIR / f\"sterilized_batch_{batch_index:04d}.pkl\"\n\n            with open(batch_path, 'wb') as f:\n                pickle.dump(vocal_segments, f)\n\n            completed = (i + 1) >= len(all_audio_files)\n            with open(STATE_FILE, 'w') as f:\n                json.dump({'cursor': i + 1, 'completed': completed}, f)\n\n            print(f\"ğŸ’¾ Saved {len(vocal_segments)} segments to {batch_path.name}. RAM cleared.\")\n            vocal_segments.clear()\n\n# â”€â”€ Aggregate: read all .pkl batches to compile the segment count â”€â”€\nprint(\"\\nğŸŸ¢ [Sterilize] Compiling dataset breakdown from disk...\")\nds_counts = defaultdict(int)\ntotal_segments = 0\n\nfor batch_file in sorted(STERILIZED_DIR.glob('*.pkl')):\n    with open(batch_file, 'rb') as f:\n        batch_data = pickle.load(f)\n        total_segments += len(batch_data)\n        for s in batch_data:\n            ds_counts[s['dataset'].split('_')[0]] += 1\n\nprint(f\"ğŸŸ¢ [Sterilize] Total sterile segments: {total_segments}\")\nfor ds, cnt in sorted(ds_counts.items()):\n    print(f\"  {ds}: {cnt}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T07:26:40.386223Z","iopub.execute_input":"2026-02-24T07:26:40.386571Z","iopub.status.idle":"2026-02-24T07:31:41.737225Z","shell.execute_reply.started":"2026-02-24T07:26:40.386546Z","shell.execute_reply":"2026-02-24T07:31:41.735640Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [Sterilize] Discovering audio files...\nğŸŸ¢ [Sterilize] Found 133835 source files\nğŸŸ¢ [Sterilize] Processing from file index 0...\n\nâš  Output size limit reached. Saving sterilization progress.\n\nğŸŸ¢ [Sterilize] Compiling dataset breakdown from disk...\nğŸŸ¢ [Sterilize] Total sterile segments: 0\n","output_type":"stream"}],"execution_count":17},{"id":"51828f09","cell_type":"markdown","source":"---\n> âš ï¸ **Phase Skip**: Phases 2â€“4 above can be skipped entirely if a previous run\n> completed them successfully. The notebook detects existing `ir_catalogue.json`,\n> `clap_cache.npz`, and `sterilize_state.json` to bypass redundant computation.\n> Previous run files are located at `/kaggle/input/notebooks/itorousa/genesis-data-run#`.\n---\n","metadata":{}},{"id":"ffa2c518","cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 5 â€” The Messy DSP Toolkit\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Random, destructive audio effects applied ONLY to the source_wet input\n# to simulate terrible recording environments.\n\ndef add_noise(audio: np.ndarray, noise_type: str, snr_db: float) -> np.ndarray:\n    '''Mix coloured noise at the target SNR (5â€“40 dB).'''\n    n = len(audio)\n    if noise_type == 'white':\n        noise = np.random.randn(n)\n    elif noise_type == 'pink':\n        freqs = np.fft.rfftfreq(n, 1 / SR)\n        freqs[0] = 1\n        S = 1.0 / np.sqrt(freqs)\n        noise = np.fft.irfft(S * np.exp(2j * np.pi * np.random.rand(len(S))))[:n]\n    elif noise_type == 'brown':\n        noise = np.cumsum(np.random.randn(n))\n        noise -= np.mean(noise)\n    elif noise_type == 'hvac':\n        noise = np.random.randn(n)\n        from scipy.signal import butter, sosfilt\n        sos = butter(4, [100, 1000], btype='band', fs=SR, output='sos')\n        noise = sosfilt(sos, noise)\n    elif noise_type == 'hum':\n        t = np.arange(n) / SR\n        base_freq = random.choice([50, 60])\n        noise = np.zeros(n)\n        for h in range(1, 6):\n            amp = 1.0 / h\n            noise += amp * np.sin(2 * np.pi * base_freq * h * t\n                                  + random.uniform(0, 2 * np.pi))\n    else:\n        noise = np.random.randn(n)\n\n    sig_power = np.mean(audio ** 2) + 1e-12\n    noise_power = np.mean(noise ** 2) + 1e-12\n    target_noise_power = sig_power / (10 ** (snr_db / 10))\n    noise = noise * np.sqrt(target_noise_power / noise_power)\n    return audio + noise.astype(np.float32)\n\n\ndef apply_eq(audio: np.ndarray) -> np.ndarray:\n    '''Random 3-band parametric EQ (simulates mic coloration).'''\n    from scipy.signal import butter, sosfilt\n    bands = [(80, 300), (300, 3000), (3000, 12000)]\n    for lo, hi in bands:\n        gain_db = random.uniform(-6, 6)\n        if abs(gain_db) < 1:\n            continue\n        try:\n            sos = butter(2, [lo, hi], btype='band', fs=SR, output='sos')\n            band_sig = sosfilt(sos, audio)\n            gain_lin = 10 ** (gain_db / 20)\n            audio = audio + band_sig * (gain_lin - 1)\n        except Exception:\n            pass\n    return audio.astype(np.float32)\n\n\ndef apply_highpass(audio: np.ndarray) -> np.ndarray:\n    from scipy.signal import butter, sosfilt\n    cutoff = random.uniform(60, 300)\n    sos = butter(4, cutoff, btype='high', fs=SR, output='sos')\n    return sosfilt(sos, audio).astype(np.float32)\n\n\ndef apply_lowpass(audio: np.ndarray) -> np.ndarray:\n    from scipy.signal import butter, sosfilt\n    cutoff = random.uniform(3000, 16000)\n    sos = butter(4, cutoff, btype='low', fs=SR, output='sos')\n    return sosfilt(sos, audio).astype(np.float32)\n\n\ndef apply_gain_jitter(audio: np.ndarray) -> np.ndarray:\n    gain_db = random.uniform(-6, 6)\n    return audio * (10 ** (gain_db / 20))\n\n\ndef apply_bitcrush(audio: np.ndarray) -> np.ndarray:\n    '''Bitcrushing / hard clipping â€” quantize audio resolution.'''\n    bits = random.randint(8, 16)\n    levels = 2 ** bits\n    return (np.round(audio * levels) / levels).astype(np.float32)\n\n\ndef apply_hard_clip(audio: np.ndarray) -> np.ndarray:\n    '''Harsh mathematical clipping at a random threshold.'''\n    threshold = random.uniform(0.3, 0.9)\n    return np.clip(audio, -threshold, threshold).astype(np.float32)\n\n\n# Registry of all degradation functions\nDEGRADATIONS = {\n    'noise':     lambda a: add_noise(a, random.choice(\n                     ['white', 'pink', 'brown', 'hvac', 'hum']),\n                     random.uniform(5, 40)),\n    'eq':        apply_eq,\n    'highpass':  apply_highpass,\n    'lowpass':   apply_lowpass,\n    'gain':      apply_gain_jitter,\n    'bitcrush':  apply_bitcrush,\n    'clip':      apply_hard_clip,\n}\n\ndef apply_random_degradations(audio: np.ndarray) -> Tuple[np.ndarray, List[str]]:\n    '''Apply a random subset of 3â€“6 degradations. Returns (degraded, names).'''\n    n_augs = random.randint(AUGMENTATIONS_MIN, AUGMENTATIONS_MAX)\n    chosen = random.sample(list(DEGRADATIONS.keys()), min(n_augs, len(DEGRADATIONS)))\n    for name in chosen:\n        audio = DEGRADATIONS[name](audio)\n    audio = np.clip(audio, -1.0, 1.0)\n    return audio.astype(np.float32), chosen\n\nprint(\"ğŸŸ¢ [Degradation] Toolkit loaded âœ“\")\nprint(f\"  Available: {list(DEGRADATIONS.keys())}\")\nprint(f\"  Per triple: {AUGMENTATIONS_MIN}â€“{AUGMENTATIONS_MAX} random degradations\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:57:33.173118Z","iopub.execute_input":"2026-02-25T08:57:33.173552Z","iopub.status.idle":"2026-02-25T08:57:33.195868Z","shell.execute_reply.started":"2026-02-25T08:57:33.173519Z","shell.execute_reply":"2026-02-25T08:57:33.194859Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [Degradation] Toolkit loaded âœ“\n  Available: ['noise', 'eq', 'highpass', 'lowpass', 'gain', 'bitcrush', 'clip']\n  Per triple: 3â€“6 random degradations\n","output_type":"stream"}],"execution_count":8},{"id":"545106be-36dd-4f89-83bc-5cf93b98a7b3","cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 6 â€” The Streaming Training Data Engine\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\ndef convolve_and_trim(vocal: np.ndarray, ir: np.ndarray) -> np.ndarray:\n    \"\"\"Convolve vocal with IR, trim to exactly 5s, peak-normalize.\"\"\"\n    wet = fftconvolve(vocal, ir, mode='full')[:CLIP_SAMPLES]\n    peak = np.max(np.abs(wet))\n    if peak > 1e-6:\n        wet = wet / peak\n    return wet.astype(np.float32)\n\ndef audio_to_int16(audio: np.ndarray) -> np.ndarray:\n    \"\"\"Convert float32 [-1,1] to int16 for compact storage.\"\"\"\n    return (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n\n# â”€â”€ Ensure IR audio is loaded â”€â”€\nif not all_irs or not any('audio' in v for v in all_irs.values() if isinstance(v, dict)):\n    print(\"ğŸŸ¢ [Engine] Lazy-loading IR audio for convolution...\")\n    def _load_ir(ir_id: str) -> Optional[np.ndarray]:\n        if ir_id.startswith('mit_'):\n            for f in MIT_IR_DIR.rglob('*.wav'):\n                if f.stem == ir_id[4:]:\n                    audio, _ = librosa.load(str(f), sr=SR, mono=True)\n                    peak = np.max(np.abs(audio))\n                    return (audio / peak).astype(np.float32) if peak > 1e-6 else audio\n        elif ir_id.startswith('user_'):\n            for ext in ('*.irs', '*.wav'):\n                for f in PATHS['irs'].rglob(ext):\n                    if f.stem == ir_id[5:]:\n                        audio, _ = librosa.load(str(f), sr=SR, mono=True)\n                        peak = np.max(np.abs(audio))\n                        return (audio / peak).astype(np.float32) if peak > 1e-6 else audio\n        return None\n\n    all_irs = {}\n    for ir_id in target_pool + bad_pool:\n        a = _load_ir(ir_id)\n        if a is not None:\n            all_irs[ir_id] = {'audio': a, 'source': ir_catalogue.get(ir_id, {}).get('source', 'unknown')}\n    print(f\"ğŸŸ¢ [Engine] Loaded {len(all_irs)} IRs\")\n\n# â”€â”€ Batch accumulators & Setup â”€â”€\nbatch_sources:  List[np.ndarray] = []\nbatch_targets:  List[np.ndarray] = []\nbatch_claps:    List[np.ndarray] = []\nbatch_meta:     List[dict]       = []\n\nclap_cache_data = dict(np.load(CLAP_CACHE_PATH))\nbatch_id  = ckpt.get('batch_id', 0)\ntotal     = ckpt.get('triples_completed', 0)\n\n# â”€â”€ Read directly from the Kaggle Input drive (0 GB disk cost) â”€â”€\nprev_sterilized_dir = PREV_RUN_PATH / 'sterilized_batches'\npkl_files = sorted(prev_sterilized_dir.glob('sterilized_batch_*.pkl'))\n\nprint(f\"\\nğŸŸ¢ [Engine] Starting streaming triple generation...\")\nprint(f\"  Found {len(pkl_files)} sterilized batches in previous run.\")\nprint(f\"  Bad pool: {len(bad_pool)}, Target pool: {len(target_pool)}\\n\")\n\nt_start = time.time()\ntriples_this_run = 0\nskipped = 0\nlimit_reached = False\n\n# â”€â”€ STREAMING LOOP â”€â”€\nfor pkl_idx, pkl_file in enumerate(pkl_files):\n    if limit_reached:\n        break\n        \n    print(f\"ğŸŸ¢ Processing {pkl_file.name} ({pkl_idx+1}/{len(pkl_files)})...\")\n    \n    with open(pkl_file, 'rb') as f:\n        chunk_segments = pickle.load(f)\n        \n    random.shuffle(chunk_segments)\n    \n    for seg in chunk_segments:\n        # â”€â”€ Budget check for Output Directory â”€â”€\n        if get_output_size_gb() > MAX_OUTPUT_GB:\n            print(f\"\\nâš ï¸ Output size limit reached ({MAX_OUTPUT_GB} GB). Stopping.\")\n            limit_reached = True\n            break\n\n        V = seg['audio']\n\n        # â”€â”€ Pick random bad IR & target IR â”€â”€\n        bad_ir_id    = random.choice(bad_pool)\n        target_ir_id = random.choice(target_pool)\n\n        if bad_ir_id not in all_irs or target_ir_id not in all_irs:\n            skipped += 1\n            continue\n\n        ir_A = all_irs[bad_ir_id]['audio']\n        ir_C = all_irs[target_ir_id]['audio']\n\n        # â”€â”€ Create target audio (ground truth): V âŠ› target_IR â”€â”€\n        target_wet = convolve_and_trim(V, ir_C)\n\n        # â”€â”€ Create messy source: (V âŠ› bad_IR) mixed with raw V â”€â”€\n        source_wet = convolve_and_trim(V, ir_A)\n        wet_dry = random.uniform(0.3, 1.0)\n        source_wet = wet_dry * source_wet + (1 - wet_dry) * V[:len(source_wet)]\n\n        # â”€â”€ Degrade source only â”€â”€\n        source_wet, aug_names = apply_random_degradations(source_wet)\n\n        # â”€â”€ QA: reject silent / NaN triples â”€â”€\n        src_rms = np.sqrt(np.mean(source_wet ** 2))\n        tgt_rms = np.sqrt(np.mean(target_wet ** 2))\n        if src_rms < 1e-4 or tgt_rms < 1e-4:\n            skipped += 1\n            continue\n        if np.any(np.isnan(source_wet)) or np.any(np.isnan(target_wet)):\n            skipped += 1\n            continue\n\n        # â”€â”€ CLAP embedding for target IR â”€â”€\n        target_clap = clap_cache_data.get(target_ir_id)\n        if target_clap is None:\n            target_clap = get_clap_audio_embedding(target_wet)\n\n        # â”€â”€ Quantize & accumulate â”€â”€\n        batch_sources.append(audio_to_int16(source_wet))\n        batch_targets.append(audio_to_int16(target_wet))\n        batch_claps.append(target_clap)\n        batch_meta.append({\n            'vocal_file':   seg['file'],\n            'dataset':      seg['dataset'],\n            'bad_ir':       bad_ir_id,\n            'target_ir':    target_ir_id,\n            'wet_dry':      round(wet_dry, 3),\n            'degradations': aug_names,\n        })\n\n        # â”€â”€ ğŸ’¾ Flush batch when full â”€â”€\n        if len(batch_sources) >= TRIPLES_PER_BATCH:\n            batch_path = BATCH_DIR / f'batch_{batch_id:04d}.npz'\n            np.savez(\n                batch_path,\n                source_audio  = np.stack(batch_sources),\n                target_audio  = np.stack(batch_targets),\n                target_clap   = np.stack(batch_claps),\n            )\n            meta_path = BATCH_DIR / f'batch_{batch_id:04d}_meta.json'\n            with open(meta_path, 'w') as f:\n                json.dump(batch_meta, f)\n\n            triples_this_run += len(batch_sources)\n            total += len(batch_sources)\n            batch_id += 1\n\n            ckpt.update({\n                'batch_id': batch_id,\n                'triples_completed': total,\n            })\n            save_checkpoint(ckpt)\n\n            elapsed = time.time() - t_start\n            rate = triples_this_run / elapsed if elapsed > 0 else 0\n            print(f\"  ğŸ’¾ Batch {batch_id-1:04d} saved | \"\n                  f\"triples: {total:,} total | \"\n                  f\"{rate:.0f}/sec | \"\n                  f\"{get_output_size_gb():.1f} GB used\")\n\n            batch_sources.clear()\n            batch_targets.clear()\n            batch_claps.clear()\n            batch_meta.clear()\n            \n    # Clear chunk from RAM after processing\n    del chunk_segments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T08:57:39.334554Z","iopub.execute_input":"2026-02-25T08:57:39.334926Z","iopub.status.idle":"2026-02-25T09:20:22.788106Z","shell.execute_reply.started":"2026-02-25T08:57:39.334895Z","shell.execute_reply":"2026-02-25T09:20:22.784733Z"}},"outputs":[{"name":"stdout","text":"\nğŸŸ¢ [Engine] Starting streaming triple generation...\n  Found 38 sterilized batches in previous run.\n  Bad pool: 270, Target pool: 389\n\nğŸŸ¢ Processing sterilized_batch_0001.pkl (1/38)...\n  ğŸ’¾ Batch 0000 saved | triples: 500 total | 16/sec | 1.2 GB used\nğŸŸ¢ Processing sterilized_batch_0002.pkl (2/38)...\n  ğŸ’¾ Batch 0001 saved | triples: 1,000 total | 15/sec | 1.6 GB used\nğŸŸ¢ Processing sterilized_batch_0003.pkl (3/38)...\n  ğŸ’¾ Batch 0002 saved | triples: 1,500 total | 15/sec | 2.1 GB used\nğŸŸ¢ Processing sterilized_batch_0004.pkl (4/38)...\n  ğŸ’¾ Batch 0003 saved | triples: 2,000 total | 16/sec | 2.5 GB used\nğŸŸ¢ Processing sterilized_batch_0005.pkl (5/38)...\n  ğŸ’¾ Batch 0004 saved | triples: 2,500 total | 15/sec | 3.0 GB used\nğŸŸ¢ Processing sterilized_batch_0006.pkl (6/38)...\n  ğŸ’¾ Batch 0005 saved | triples: 3,000 total | 15/sec | 3.4 GB used\nğŸŸ¢ Processing sterilized_batch_0007.pkl (7/38)...\n  ğŸ’¾ Batch 0006 saved | triples: 3,500 total | 15/sec | 3.9 GB used\nğŸŸ¢ Processing sterilized_batch_0008.pkl (8/38)...\n  ğŸ’¾ Batch 0007 saved | triples: 4,000 total | 15/sec | 4.3 GB used\nğŸŸ¢ Processing sterilized_batch_0009.pkl (9/38)...\n  ğŸ’¾ Batch 0008 saved | triples: 4,500 total | 15/sec | 4.8 GB used\nğŸŸ¢ Processing sterilized_batch_0010.pkl (10/38)...\n  ğŸ’¾ Batch 0009 saved | triples: 5,000 total | 15/sec | 5.2 GB used\nğŸŸ¢ Processing sterilized_batch_0011.pkl (11/38)...\n  ğŸ’¾ Batch 0010 saved | triples: 5,500 total | 15/sec | 5.7 GB used\nğŸŸ¢ Processing sterilized_batch_0012.pkl (12/38)...\n  ğŸ’¾ Batch 0011 saved | triples: 6,000 total | 15/sec | 6.1 GB used\n  ğŸ’¾ Batch 0012 saved | triples: 6,500 total | 15/sec | 6.6 GB used\nğŸŸ¢ Processing sterilized_batch_0013.pkl (13/38)...\n  ğŸ’¾ Batch 0013 saved | triples: 7,000 total | 15/sec | 7.0 GB used\nğŸŸ¢ Processing sterilized_batch_0014.pkl (14/38)...\n  ğŸ’¾ Batch 0014 saved | triples: 7,500 total | 15/sec | 7.5 GB used\nğŸŸ¢ Processing sterilized_batch_0015.pkl (15/38)...\n  ğŸ’¾ Batch 0015 saved | triples: 8,000 total | 15/sec | 7.9 GB used\nğŸŸ¢ Processing sterilized_batch_0016.pkl (16/38)...\n  ğŸ’¾ Batch 0016 saved | triples: 8,500 total | 15/sec | 8.4 GB used\nğŸŸ¢ Processing sterilized_batch_0017.pkl (17/38)...\n  ğŸ’¾ Batch 0017 saved | triples: 9,000 total | 15/sec | 8.8 GB used\nğŸŸ¢ Processing sterilized_batch_0018.pkl (18/38)...\n  ğŸ’¾ Batch 0018 saved | triples: 9,500 total | 15/sec | 9.3 GB used\nğŸŸ¢ Processing sterilized_batch_0019.pkl (19/38)...\n  ğŸ’¾ Batch 0019 saved | triples: 10,000 total | 15/sec | 9.7 GB used\nğŸŸ¢ Processing sterilized_batch_0020.pkl (20/38)...\n  ğŸ’¾ Batch 0020 saved | triples: 10,500 total | 15/sec | 10.2 GB used\nğŸŸ¢ Processing sterilized_batch_0021.pkl (21/38)...\n  ğŸ’¾ Batch 0021 saved | triples: 11,000 total | 15/sec | 10.6 GB used\nğŸŸ¢ Processing sterilized_batch_0022.pkl (22/38)...\n  ğŸ’¾ Batch 0022 saved | triples: 11,500 total | 15/sec | 11.0 GB used\nğŸŸ¢ Processing sterilized_batch_0023.pkl (23/38)...\n  ğŸ’¾ Batch 0023 saved | triples: 12,000 total | 15/sec | 11.5 GB used\nğŸŸ¢ Processing sterilized_batch_0024.pkl (24/38)...\n  ğŸ’¾ Batch 0024 saved | triples: 12,500 total | 15/sec | 11.9 GB used\n  ğŸ’¾ Batch 0025 saved | triples: 13,000 total | 15/sec | 12.4 GB used\nğŸŸ¢ Processing sterilized_batch_0025.pkl (25/38)...\n  ğŸ’¾ Batch 0026 saved | triples: 13,500 total | 15/sec | 12.8 GB used\nğŸŸ¢ Processing sterilized_batch_0026.pkl (26/38)...\n  ğŸ’¾ Batch 0027 saved | triples: 14,000 total | 15/sec | 13.3 GB used\nğŸŸ¢ Processing sterilized_batch_0027.pkl (27/38)...\n  ğŸ’¾ Batch 0028 saved | triples: 14,500 total | 15/sec | 13.7 GB used\nğŸŸ¢ Processing sterilized_batch_0028.pkl (28/38)...\n  ğŸ’¾ Batch 0029 saved | triples: 15,000 total | 15/sec | 14.2 GB used\nğŸŸ¢ Processing sterilized_batch_0029.pkl (29/38)...\n  ğŸ’¾ Batch 0030 saved | triples: 15,500 total | 15/sec | 14.6 GB used\nğŸŸ¢ Processing sterilized_batch_0030.pkl (30/38)...\n  ğŸ’¾ Batch 0031 saved | triples: 16,000 total | 15/sec | 15.1 GB used\nğŸŸ¢ Processing sterilized_batch_0031.pkl (31/38)...\n  ğŸ’¾ Batch 0032 saved | triples: 16,500 total | 15/sec | 15.5 GB used\nğŸŸ¢ Processing sterilized_batch_0032.pkl (32/38)...\n  ğŸ’¾ Batch 0033 saved | triples: 17,000 total | 15/sec | 16.0 GB used\nğŸŸ¢ Processing sterilized_batch_0033.pkl (33/38)...\n  ğŸ’¾ Batch 0034 saved | triples: 17,500 total | 15/sec | 16.4 GB used\nğŸŸ¢ Processing sterilized_batch_0034.pkl (34/38)...\n  ğŸ’¾ Batch 0035 saved | triples: 18,000 total | 15/sec | 16.9 GB used\nğŸŸ¢ Processing sterilized_batch_0035.pkl (35/38)...\n  ğŸ’¾ Batch 0036 saved | triples: 18,500 total | 15/sec | 17.3 GB used\n  ğŸ’¾ Batch 0037 saved | triples: 19,000 total | 15/sec | 17.8 GB used\nğŸŸ¢ Processing sterilized_batch_0036.pkl (36/38)...\n  ğŸ’¾ Batch 0038 saved | triples: 19,500 total | 15/sec | 18.2 GB used\nğŸŸ¢ Processing sterilized_batch_0037.pkl (37/38)...\n  ğŸ’¾ Batch 0039 saved | triples: 20,000 total | 15/sec | 18.7 GB used\nğŸŸ¢ Processing sterilized_batch_0038.pkl (38/38)...\n  ğŸ’¾ Batch 0040 saved | triples: 20,500 total | 15/sec | 19.1 GB used\n\nâš ï¸ Output size limit reached (19.0 GB). Stopping.\n","output_type":"stream"}],"execution_count":9},{"id":"7d0c46af","cell_type":"markdown","source":"---\n> âš ï¸ **Phase Skip**: Phases 5â€“6 above can be skipped if a previous run already\n> generated sufficient training batches. Attach the previous output as input and\n> the checkpoint system will resume from where it left off.\n---\n","metadata":{}},{"id":"5a65a23a","cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 7 â€” Manifest & Pipeline Conclusion\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# â”€â”€ Flush any remaining triples (<500) â”€â”€\nif batch_sources:\n    batch_path = BATCH_DIR / f'batch_{batch_id:04d}.npz'\n    np.savez(\n        batch_path,\n        source_audio = np.stack(batch_sources),\n        target_audio = np.stack(batch_targets),\n        target_clap  = np.stack(batch_claps),\n    )\n    meta_path = BATCH_DIR / f'batch_{batch_id:04d}_meta.json'\n    with open(meta_path, 'w') as f:\n        json.dump(batch_meta, f)\n\n    triples_this_run += len(batch_sources)\n    total += len(batch_sources)\n    batch_id += 1\n\n    ckpt.update({\n        'batch_id': batch_id,\n        'triples_completed': total,\n        'vocal_cursor': len(vocal_segments),\n    })\n    save_checkpoint(ckpt)\n\nelapsed = time.time() - t_start\n\n# â”€â”€ SHA-256 checksums â”€â”€\ndef sha256_file(path: Path) -> str:\n    h = hashlib.sha256()\n    with open(path, 'rb') as f:\n        for chunk in iter(lambda: f.read(8192), b''):\n            h.update(chunk)\n    return h.hexdigest()\n\nmanifest = {\n    'run_number':        ckpt['run_number'],\n    'triples_total':     ckpt['triples_completed'],\n    'batches':           ckpt['batch_id'],\n    'sample_rate':       SR,\n    'clip_seconds':      CLIP_SEC,\n    'clip_samples':      CLIP_SAMPLES,\n    'clap_dim':          CLAP_DIM,\n    'bad_pool_size':     len(bad_pool),\n    'target_pool_size':  len(target_pool),\n    'output_size_gb':    round(get_output_size_gb(), 3),\n    'batch_checksums':   {},\n}\n\nprint(\"[Manifest] Computing SHA-256 checksums...\")\nfor f in sorted(BATCH_DIR.glob('batch_*.npz')):\n    manifest['batch_checksums'][f.name] = sha256_file(f)\n\nwith open(OUTPUT / 'manifest.json', 'w') as f:\n    json.dump(manifest, f, indent=2)\n\nprint(f\"[Manifest] Saved âœ“\")\nprint(f\"\\n{'='*60}\")\nprint(f\"  GENESIS DATA CURATION â€” RUN {ckpt['run_number']} COMPLETE\")\nprint(f\"{'='*60}\")\nprint(f\"  Total triples:   {manifest['triples_total']:,}\")\nprint(f\"  Batches:          {manifest['batches']}\")\nprint(f\"  Output size:      {manifest['output_size_gb']:.2f} GB\")\nprint(f\"  CLAP dim:         {manifest['clap_dim']}\")\nprint(f\"  Elapsed:          {elapsed/60:.1f} min\")\nprint(f\"{'='*60}\")\n\nif ckpt['vocal_cursor'] < len(vocal_segments):\n    remaining = len(vocal_segments) - ckpt['vocal_cursor']\n    print(f\"\\nâš   {remaining} vocal segments remaining.\")\n    print(f\"  To continue:\")\n    print(f\"    1. Save this notebook's output as a Kaggle dataset\")\n    print(f\"    2. Update PREV_RUN_PATH in Cell 3 to point to it\")\n    print(f\"    3. Create a new notebook, attach the same input datasets\")\n    print(f\"    4. Run all cells â€” the checkpoint system will resume\")\nelse:\n    print(f\"\\nğŸŸ¢ All vocal segments processed. Dataset complete!\")\n    print(f\"   Output is ready for Genesis's STFT Dataloader in the training phase.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T09:37:22.593786Z","iopub.execute_input":"2026-02-25T09:37:22.596872Z","iopub.status.idle":"2026-02-25T09:39:08.051792Z","shell.execute_reply.started":"2026-02-25T09:37:22.596761Z","shell.execute_reply":"2026-02-25T09:39:08.049721Z"}},"outputs":[{"name":"stdout","text":"[Manifest] Computing SHA-256 checksums...\n[Manifest] Saved âœ“\n\n============================================================\n  GENESIS DATA CURATION â€” RUN 2 COMPLETE\n============================================================\n  Total triples:   20,500\n  Batches:          41\n  Output size:      19.11 GB\n  CLAP dim:         512\n  Elapsed:          39.7 min\n============================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2825657617.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'='*60}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocal_cursor'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocal_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocal_segments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocal_cursor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nâš   {remaining} vocal segments remaining.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'vocal_segments' is not defined"],"ename":"NameError","evalue":"name 'vocal_segments' is not defined","output_type":"error"}],"execution_count":10},{"id":"1e1d4b25-212b-489e-be61-16143bdc59b9","cell_type":"code","source":"from pathlib import Path\n\ndef print_tree(dir_path=\"/kaggle/working\"):\n    base = Path(dir_path)\n    \n    if not base.exists():\n        print(f\"ğŸ”´ Directory not found: {dir_path}\")\n        return\n        \n    print(f\"ğŸŸ¢ {base.resolve()}\")\n    \n    # Recursively grab everything and sort it\n    for path in sorted(base.rglob('*')):\n        depth = len(path.relative_to(base).parts)\n        # Create the branching indentation\n        indent = 'â”‚   ' * (depth - 1) + 'â”œâ”€â”€ '\n        print(f\"{indent}{path.name}\")\n\n# Run it\nprint_tree()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T09:47:01.083464Z","iopub.execute_input":"2026-02-25T09:47:01.084687Z","iopub.status.idle":"2026-02-25T09:47:01.143005Z","shell.execute_reply.started":"2026-02-25T09:47:01.084644Z","shell.execute_reply":"2026-02-25T09:47:01.141661Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ /kaggle/working\nâ”œâ”€â”€ .virtual_documents\nâ”‚   â”œâ”€â”€ __notebook_source__.ipynb\nâ”œâ”€â”€ batches\nâ”‚   â”œâ”€â”€ batch_0000.npz\nâ”‚   â”œâ”€â”€ batch_0000_meta.json\nâ”‚   â”œâ”€â”€ batch_0001.npz\nâ”‚   â”œâ”€â”€ batch_0001_meta.json\nâ”‚   â”œâ”€â”€ batch_0002.npz\nâ”‚   â”œâ”€â”€ batch_0002_meta.json\nâ”‚   â”œâ”€â”€ batch_0003.npz\nâ”‚   â”œâ”€â”€ batch_0003_meta.json\nâ”‚   â”œâ”€â”€ batch_0004.npz\nâ”‚   â”œâ”€â”€ batch_0004_meta.json\nâ”‚   â”œâ”€â”€ batch_0005.npz\nâ”‚   â”œâ”€â”€ batch_0005_meta.json\nâ”‚   â”œâ”€â”€ batch_0006.npz\nâ”‚   â”œâ”€â”€ batch_0006_meta.json\nâ”‚   â”œâ”€â”€ batch_0007.npz\nâ”‚   â”œâ”€â”€ batch_0007_meta.json\nâ”‚   â”œâ”€â”€ batch_0008.npz\nâ”‚   â”œâ”€â”€ batch_0008_meta.json\nâ”‚   â”œâ”€â”€ batch_0009.npz\nâ”‚   â”œâ”€â”€ batch_0009_meta.json\nâ”‚   â”œâ”€â”€ batch_0010.npz\nâ”‚   â”œâ”€â”€ batch_0010_meta.json\nâ”‚   â”œâ”€â”€ batch_0011.npz\nâ”‚   â”œâ”€â”€ batch_0011_meta.json\nâ”‚   â”œâ”€â”€ batch_0012.npz\nâ”‚   â”œâ”€â”€ batch_0012_meta.json\nâ”‚   â”œâ”€â”€ batch_0013.npz\nâ”‚   â”œâ”€â”€ batch_0013_meta.json\nâ”‚   â”œâ”€â”€ batch_0014.npz\nâ”‚   â”œâ”€â”€ batch_0014_meta.json\nâ”‚   â”œâ”€â”€ batch_0015.npz\nâ”‚   â”œâ”€â”€ batch_0015_meta.json\nâ”‚   â”œâ”€â”€ batch_0016.npz\nâ”‚   â”œâ”€â”€ batch_0016_meta.json\nâ”‚   â”œâ”€â”€ batch_0017.npz\nâ”‚   â”œâ”€â”€ batch_0017_meta.json\nâ”‚   â”œâ”€â”€ batch_0018.npz\nâ”‚   â”œâ”€â”€ batch_0018_meta.json\nâ”‚   â”œâ”€â”€ batch_0019.npz\nâ”‚   â”œâ”€â”€ batch_0019_meta.json\nâ”‚   â”œâ”€â”€ batch_0020.npz\nâ”‚   â”œâ”€â”€ batch_0020_meta.json\nâ”‚   â”œâ”€â”€ batch_0021.npz\nâ”‚   â”œâ”€â”€ batch_0021_meta.json\nâ”‚   â”œâ”€â”€ batch_0022.npz\nâ”‚   â”œâ”€â”€ batch_0022_meta.json\nâ”‚   â”œâ”€â”€ batch_0023.npz\nâ”‚   â”œâ”€â”€ batch_0023_meta.json\nâ”‚   â”œâ”€â”€ batch_0024.npz\nâ”‚   â”œâ”€â”€ batch_0024_meta.json\nâ”‚   â”œâ”€â”€ batch_0025.npz\nâ”‚   â”œâ”€â”€ batch_0025_meta.json\nâ”‚   â”œâ”€â”€ batch_0026.npz\nâ”‚   â”œâ”€â”€ batch_0026_meta.json\nâ”‚   â”œâ”€â”€ batch_0027.npz\nâ”‚   â”œâ”€â”€ batch_0027_meta.json\nâ”‚   â”œâ”€â”€ batch_0028.npz\nâ”‚   â”œâ”€â”€ batch_0028_meta.json\nâ”‚   â”œâ”€â”€ batch_0029.npz\nâ”‚   â”œâ”€â”€ batch_0029_meta.json\nâ”‚   â”œâ”€â”€ batch_0030.npz\nâ”‚   â”œâ”€â”€ batch_0030_meta.json\nâ”‚   â”œâ”€â”€ batch_0031.npz\nâ”‚   â”œâ”€â”€ batch_0031_meta.json\nâ”‚   â”œâ”€â”€ batch_0032.npz\nâ”‚   â”œâ”€â”€ batch_0032_meta.json\nâ”‚   â”œâ”€â”€ batch_0033.npz\nâ”‚   â”œâ”€â”€ batch_0033_meta.json\nâ”‚   â”œâ”€â”€ batch_0034.npz\nâ”‚   â”œâ”€â”€ batch_0034_meta.json\nâ”‚   â”œâ”€â”€ batch_0035.npz\nâ”‚   â”œâ”€â”€ batch_0035_meta.json\nâ”‚   â”œâ”€â”€ batch_0036.npz\nâ”‚   â”œâ”€â”€ batch_0036_meta.json\nâ”‚   â”œâ”€â”€ batch_0037.npz\nâ”‚   â”œâ”€â”€ batch_0037_meta.json\nâ”‚   â”œâ”€â”€ batch_0038.npz\nâ”‚   â”œâ”€â”€ batch_0038_meta.json\nâ”‚   â”œâ”€â”€ batch_0039.npz\nâ”‚   â”œâ”€â”€ batch_0039_meta.json\nâ”‚   â”œâ”€â”€ batch_0040.npz\nâ”‚   â”œâ”€â”€ batch_0040_meta.json\nâ”œâ”€â”€ checkpoint.json\nâ”œâ”€â”€ clap_cache.npz\nâ”œâ”€â”€ clap_model\nâ”‚   â”œâ”€â”€ config.json\nâ”‚   â”œâ”€â”€ model.safetensors\nâ”‚   â”œâ”€â”€ processor_config.json\nâ”‚   â”œâ”€â”€ tokenizer.json\nâ”‚   â”œâ”€â”€ tokenizer_config.json\nâ”œâ”€â”€ ir_catalogue.json\nâ”œâ”€â”€ irs\nâ”‚   â”œâ”€â”€ mit_irs\nâ”‚   â”‚   â”œâ”€â”€ Audio\nâ”‚   â”‚   â”‚   â”œâ”€â”€ .DS_Store\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h001_Bedroom_65txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h002_Bedroom_62txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h003_Office_LargeBrickWalledOpenPlanOffice_56txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h004_LivingRoom_Large_48txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h005_Office_Small_44txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h006_Bedroom_42txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h007_Bathroom_Small_41txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h008_Bedroom_35txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h009_Office_32txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h010_Livingroom_31txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h011_Car_29txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h012_Kitchen_22txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h013_Hospital_ExaminationRoom_19txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h014_HomeExerciseRoom_18txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h015_Bedroom_174txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h016_MasterBedroom_15txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h017_Livingroom_152txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h018_Kitchen_12txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h019_MITCampus_Atrium_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h020_Livingroom_10txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h021_Bedroom_102txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h022_Office_Foyer_9txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h023_Bedroom_9txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h024_Bathroom_9txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h025_Diningroom_8txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h026_Gym_8txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h027_Classroom_8txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h028_Classroom_8txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h029_BabysRoom_8txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h030_Campground_AFrameCabin_8txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h031_Bedroom_7txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h032_Bedroom_6txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h033_Classroom_6txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h034_Classroom_6txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h035_Bar_LargeSportsBar_5txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h036_Bathroom_5txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h037_Classroom_5txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h038_2ndFloorBalconyOfWoodenHouse_5txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h039_Classroom_5txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h040_Clasroom_5txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h041_TrainStation_SouthStationBoston_4txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h042_Hallway_ElementarySchool_4txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h043_Train_BostonTRedLine_4txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h044_ParkingLot_4txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h045_Livingroom_4txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h046_SuburbanGarage_4txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h047_Hallway_MIT_4txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h048_Bathroom_MITCampus_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h049_MallFoodCourt_BurlingtonMall_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h050_Bar_IrishPub_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h051_SuperMarket_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h052_Gym_WeightRoom_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h053_Office_ConferenceRoom_stxts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h054_Kitchen_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h055_Hallway_House_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h056_Outside_HarvardBridgeBetweenCambridgeAndBoston_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h057_Outside_SuburbanDriveway_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h058_Campground_Dininghall_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h059_Outside_StreetsOfCambridge_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h060_Office_ConferenceRoom_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h061_Car_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h062_Campground_Dininghall_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h063_Cafeteria_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h064_Classroom_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h065_Classroom_3txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h066_MITCampus_StudentLounge_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h067_Bar_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h068_SwimmingPool_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h069_Supermarket_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h070_Outdoor_MITBrickAmpitheater_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h071_Shower_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h072_Bar_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h073_MITCampus_StudentLounge_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h074_Outside_StreetsOfCambridge_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h075_Hallway_Office_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h076_OfficeBathroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h077_MITCampus_StudentLounge_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h078_Bar_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h079_Bar_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h080_Outdoor_GrassyField_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h081_Shower_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h082_HomeFoyer_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h083_Outside_ParkingLot_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h084_Outside_SuburbanBackyard_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h085_Bar_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h086_Bar_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h087_ArtGallery_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h088_Outside_SuburbanDriveway_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h089_MITCampus_StudentLounge_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h090_Outside_StreetsOfCambridge_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h091_Bar_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h092_Office_ConferenceRoom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h093_Restaurant_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h094_Campground_CabinLivingroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h095_Campground_Cabin_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h096_Hotel_Ballroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h097_MITCampus_Atrium_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h098_Bedroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h099_Classroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h100_Classroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h101_Classroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h102_Stairwell_ElementraySchool_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h103_Classroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h104_Classroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h105_Classroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h106_Classroom_2txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h107_Supermerket_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h108_MITCampus_ComputerRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h109_CoffeeShop_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h110_Office_MeetingRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h111_Kitchen_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h112_Bookstore_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h113_IceCreamParlor_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h114_Restaurant_txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h115_MovieTheater_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h116_SuperMarket_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h117_MITCampus_Atrium_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h118_MITCampus_Atrium_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h119_BasementStorage_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h120_Gym_WeightRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h121_MITCampus_Atrium_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h122_CoffeeShop_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h123_WineBar_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h124_Outside_MITCampusCourtyard_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h125_Bar_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h126_Outside_Skatepark.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h127_Supermarket_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h128_Supermarket_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h129_Supermarket_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h130_Restaurant_1txs.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h131_Outside_PathAroundResevoir_1txs.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h132_ToyStore_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h133_SubwayStation_ParkStreetBoston_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h134_ParkingLot_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h135_KitchePantry_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h136_SamdwichShop_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h137_Outside_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h138_Outside_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h139_OutsideStreetsOfBoston_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h140_Outside_StreetsOfSomerville_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h141_Outside_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h142_Outside_StreetsOfBoston_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h143_Outside_StreetsOfBoston_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h144_Outside_StreetsOfSomerville_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h145_Outside_StreetsOfBoston_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h146_Outside_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h147_Outside_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h148_Outside_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h149_Outside_StreetsOfSomerville_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h150_Outside_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h151_Train_BostonTOrangeLine_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h152_OfficeBathroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h153_Office_Foyer_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h154_OfficeKitchen_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h155_FastFoodRestaurant_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h156_Outside_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h157_ArtGallery_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h158_HospitalWaitingRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h159_DocrorsOffice_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h160_DepartmentStore_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h161_MITCampus_Atrium_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h162_Outside_Playground_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h163_Bathroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h164_Restaurant_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h165_Bar_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h166_MITDormLobby_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h167_Outside_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h168_Outside_StreetsOfcambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h169_IceCreamParlor_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h170_Outside_BikePath_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h171_Outside_BikePath_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h172_Outside_EntranceOfLexingtonPublicLibrary_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h173_Offixe_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h174_Bar_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h175_ParkingLot_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h176_LivingRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h177_MITCampus_LaundryRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h178_OfficeFoyer_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h179_Bar_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h180_Outside_Field_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h181_Hallway_MITInfiniteCorridor_1txs.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h182_Hallway_MITInfiniteCorridor_1txt.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h183_BackPorchOfSuburbanHome_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h184_BilliardsRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h185_Hallway_House_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h186_Outside_SoccerField_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h187_Outside_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h188_Bar_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h189_Outside_GravelPathThroughForest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h190_Train_BostonTGreenline_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h191_Kitchen_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h192_PorchOfSuburbanHouse_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h193_LivingRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h194_Outside_SuburbanDriveway_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h195_Outside_SuburbanFronyYard_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h196_FastFoodRestaurant_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h197_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h198_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h199_Outside_DoorstepOfHouseInCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h200_DryCleaners_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h201_MITCampus_DramaRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h202_Diningroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h203_Outside_StreetsOfSomerville_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h204_Outside_Forest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h205_Outside_Forest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h206_Outside_Forest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h207_Outside_Forest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h208_Outside_Forest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h209_Outside_Forest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h210_Outside_Forest_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h211_Stairwell_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h212_Outside_StreetsOfSomerville_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h213_SubwayStation_CentralSquareCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h214_Pizzeria_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h215_SandwichShop_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h216_Outside_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h217_Outside_StreetsOfcambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h218_StreetsOfBoston_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h219_StreetsOfCambridge_1txs.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h220_StreetsOfcambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h221_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h222_StreetsOfcambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h223_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h224_StreetsOfBoston_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h225_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h226_Pizzeria_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h227_Outside_ParkingLot_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h228_Outside_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h229_Office_Lobby_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h230_SuburbanBackyard_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h231_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h232_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h234_Bathroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h235_Outside_Field_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h236_BostonPubliLibrary_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h237_Classroom_1txs.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h238_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h239_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h240_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h241_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h242_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h243_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h244_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h245_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h246_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h247_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h248_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h249_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h250_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h251_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h252_Auditorium_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h253_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h254_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h255_MITCampus_StudentLounge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h256_Stairwell_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h257_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h258_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h259_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h260_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h261_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h262_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h263_Outside_StreetsOfCambridge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h264_Hallway_MITCampus_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h265_Classroom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h266_MITCampus_StduentLounge_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h267_MITCampus_Atrium_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h268_BasementOfSuburbanHome_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h269_Office_ConferenceRoom_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h270_Hallway_House_1txts.wav\nâ”‚   â”‚   â”‚   â”œâ”€â”€ h271_Outside_InTramStopRainShelter_2txts.wav\nâ”‚   â”‚   â”œâ”€â”€ __MACOSX\nâ”‚   â”‚   â”‚   â”œâ”€â”€ Audio\nâ”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ._.DS_Store\nâ”œâ”€â”€ manifest.json\nâ”œâ”€â”€ sterilized_batches\n","output_type":"stream"}],"execution_count":11},{"id":"8148d746","cell_type":"markdown","source":"## ğŸ”— Checkpoint Chaining (20 GB Limit)\n\nIf the output hit the size limit before processing all vocals:\n\n1. **Save this notebook's output** as a Kaggle dataset (e.g. `genesis-data-run1`)\n2. **Create a new notebook** (or re-run this one) and attach:\n   - All the same input datasets (IRs, LJSpeech, VCTK, Language Identifier)\n   - The previous output as input (update `PREV_RUN_PATH` in Cell 3)\n3. **Run all cells** â€” the checkpoint system automatically skips completed work\n\nEach run produces ~19 GB of training triples. Chain as many times as needed.\n\n### Using the Data in Training\n\n```python\n# In the training notebook, load all batches from all runs:\nimport numpy as np\nfrom pathlib import Path\n\nrun_dirs = [\n    Path('/kaggle/input/genesis-data-run1/batches'),\n    Path('/kaggle/input/genesis-data-run2/batches'),\n    # ... add more runs\n]\n\nfor run_dir in run_dirs:\n    for batch_file in sorted(run_dir.glob('batch_*.npz')):\n        data = np.load(batch_file)\n        source_audio = data['source_audio']   # (N, 240000) int16\n        target_audio = data['target_audio']   # (N, 240000) int16\n        target_clap  = data['target_clap']    # (N, CLAP_DIM) float32\n        # Convert int16 back to float32: audio = source_audio.astype(np.float32) / 32767\n        # Compute STFT on-the-fly during training for memory efficiency\n```\n","metadata":{}}]}