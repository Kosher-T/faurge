{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14927063,"datasetId":9551535,"databundleVersionId":15794187},{"sourceType":"datasetVersion","sourceId":101413,"datasetId":53291,"databundleVersionId":103953},{"sourceType":"datasetVersion","sourceId":4588404,"datasetId":2675000,"databundleVersionId":4649793}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q noisereduce pyloudnorm soundfile librosa transformers torch\n\nimport os, json, hashlib, time, random, warnings, shutil, pickle\nfrom pathlib import Path\nfrom typing import Optional, List, Dict, Tuple\nfrom collections import defaultdict\n\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom scipy.signal import fftconvolve\nimport noisereduce as nr\nimport torch\nfrom transformers import ClapModel, ClapProcessor\nimport pyloudnorm as pyln\n\nwarnings.filterwarnings('ignore')\nrandom.seed(42)\nnp.random.seed(42)\n\nprint(\"ğŸŸ¢ [Setup] Libraries imported and deterministic seeds set.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:39:28.796906Z","iopub.execute_input":"2026-02-26T03:39:28.797229Z","iopub.status.idle":"2026-02-26T03:39:33.122607Z","shell.execute_reply.started":"2026-02-26T03:39:28.797205Z","shell.execute_reply":"2026-02-26T03:39:33.121155Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [Setup] Libraries imported and deterministic seeds set.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Wipe Kaggle's Output Storage","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\nworking_dir = '/kaggle/working'\n\nprint(\"ğŸŸ¡ Wiping Kaggle working directory...\")\n\nfor item in os.listdir(working_dir):\n    item_path = os.path.join(working_dir, item)\n    try:\n        if os.path.isfile(item_path) or os.path.islink(item_path):\n            os.unlink(item_path)\n        elif os.path.isdir(item_path):\n            shutil.rmtree(item_path)\n    except Exception as e:\n        print(f\"ğŸ”´ Failed to delete {item_path}. Reason: {e}\")\n\nprint(\"ğŸŸ¢ Kaggle working directory is completely clean.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:39:33.125330Z","iopub.execute_input":"2026-02-26T03:39:33.125858Z","iopub.status.idle":"2026-02-26T03:39:33.545223Z","shell.execute_reply.started":"2026-02-26T03:39:33.125821Z","shell.execute_reply":"2026-02-26T03:39:33.544140Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¡ Wiping Kaggle working directory...\nğŸŸ¢ Kaggle working directory is completely clean.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### Wipe a Specific Folder/File","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\ndef delete_target(target_path):\n    target = Path(target_path)\n    \n    if not target.exists():\n        print(f\"ğŸŸ¡ Target does not exist: {target}\")\n        return\n        \n    try:\n        if target.is_file() or target.is_symlink():\n            target.unlink()\n            print(f\"ğŸŸ¢ Successfully deleted file: {target}\")\n        elif target.is_dir():\n            shutil.rmtree(target)\n            print(f\"ğŸŸ¢ Successfully deleted directory: {target}\")\n    except Exception as e:\n        print(f\"ğŸ”´ Failed to delete {target}. Reason: {e}\")\n\n# Just drop your path here\ndelete_target('//kaggle/working/ir_catalogue.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:39:33.546647Z","iopub.execute_input":"2026-02-26T03:39:33.547018Z","iopub.status.idle":"2026-02-26T03:39:33.556947Z","shell.execute_reply.started":"2026-02-26T03:39:33.546982Z","shell.execute_reply":"2026-02-26T03:39:33.555639Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¡ Target does not exist: //kaggle/working/ir_catalogue.json\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 0 â€” Environment & Path Configuration\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# KAGGLE INPUT PATHS\nPATHS = {\n    'bad_irs':   Path('/kaggle/input/datasets/itorousa/impulse-responses'),\n    'mit_irs':   Path('/kaggle/input/datasets/kynthesis/mit-reverb-dataset/MIT_Reverb_Dataset/MIT_Reverb_Dataset'),\n    'ljspeech':  Path('/kaggle/input/datasets/dromosys/ljspeech/'),\n    'vctk':      Path('/kaggle/input/datasets/kynthesis/vctk-corpus/VCTK-Corpus/wav48'),\n#   'langid_en': Path('/kaggle/input/datasets/shrivatssudhir/language-identifier/english/clips')\n}\n\n# âš ï¸ UPDATE THIS PATH WHEN CHAINING RUNS âš ï¸\nPREV_RUN_PATH = Path('/kaggle/input/notebooks/itorousa/genesis-data-run1')\n\n# OUTPUT PATHS\nOUTPUT          = Path('/kaggle/working')\nBATCH_DIR       = OUTPUT / 'batches'\nCLAP_DIR        = OUTPUT / 'clap_model'\nSTERILIZED_DIR  = OUTPUT / 'sterilized_batches'\nMIT_IR_DIR      = OUTPUT / 'irs' / 'mit_irs'\n\nfor d in [BATCH_DIR, CLAP_DIR, STERILIZED_DIR, MIT_IR_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n\n# AUDIO PARAMETERS & BUDGET\nSR            = 48_000\nCLIP_SEC      = 5.0\nCLIP_SAMPLES  = int(SR * CLIP_SEC)\nTRIPLES_PER_BATCH  = 500\nMAX_OUTPUT_GB      = 19.0 \n\nprint(f\"ğŸŸ¢ [Config] Output budget: {MAX_OUTPUT_GB} GB | SR: {SR} | Batch Size: {TRIPLES_PER_BATCH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:39:33.558729Z","iopub.execute_input":"2026-02-26T03:39:33.559207Z","iopub.status.idle":"2026-02-26T03:39:33.581945Z","shell.execute_reply.started":"2026-02-26T03:39:33.559150Z","shell.execute_reply":"2026-02-26T03:39:33.580858Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [Config] Output budget: 19.0 GB | SR: 48000 | Batch Size: 500\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 1 â€” Aggressive Checkpoint Initialization\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCHECKPOINT_PATH = OUTPUT / 'checkpoint.json'\n\ndef get_output_size_gb() -> float:\n    '''Calculate the exact size of /kaggle/working in GB.'''\n    total = sum(f.stat().st_size for f in OUTPUT.rglob('*') if f.is_file())\n    return total / (1024 ** 3)\n\ndef load_checkpoint() -> dict:\n    # 1) Check previous run first (chaining)\n    prev_ckpt = PREV_RUN_PATH / 'checkpoint.json'\n    if prev_ckpt.exists():\n        with open(prev_ckpt) as f:\n            ckpt = json.load(f)\n        ckpt['run_number'] += 1\n        print(f\"ğŸŸ¢ [Checkpoint] â™» Resuming from previous run: {ckpt['triples_completed']} triples done\")\n        return ckpt\n\n    # 2) Check current working dir (kernel restart mid-session)\n    if CHECKPOINT_PATH.exists():\n        with open(CHECKPOINT_PATH) as f:\n            return json.load(f)\n\n    # 3) Fresh start\n    return {\n        'batch_id': 0,\n        'triples_completed': 0,\n        'vocal_cursor': 0,\n        'run_number': 1,\n    }\n\ndef save_checkpoint(ckpt: dict):\n    with open(CHECKPOINT_PATH, 'w') as f:\n        json.dump(ckpt, f, indent=2)\n\nckpt = load_checkpoint()\nsave_checkpoint(ckpt) # Initialize immediately\n\nprint(f\"ğŸŸ¢ [Checkpoint] Run #{ckpt['run_number']} | Starting at vocal cursor {ckpt['vocal_cursor']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:39:33.584939Z","iopub.execute_input":"2026-02-26T03:39:33.585841Z","iopub.status.idle":"2026-02-26T03:39:33.611656Z","shell.execute_reply.started":"2026-02-26T03:39:33.585806Z","shell.execute_reply":"2026-02-26T03:39:33.610568Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [Checkpoint] Run #1 | Starting at vocal cursor 0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import urllib.request\nimport zipfile\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 2 â€” Impulse Response Acquisition & Pooling\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCATALOGUE_PATH = OUTPUT / 'ir_catalogue.json'\nprev_catalogue = PREV_RUN_PATH / 'ir_catalogue.json'\nprev_mit_irs = PREV_RUN_PATH / 'irs' / 'mit_irs'\nMIT_RAW_URL = 'https://mcdermottlab.mit.edu/Reverb/IRMAudio/Audio.zip'\n\nbad_pool: List[str] = []\ntarget_pool: List[str] = []\nir_catalogue: Dict = {}\n\n# â”€â”€â”€ Fast path: Copy from previous run if exists â”€â”€â”€\nif prev_catalogue.exists() and not CATALOGUE_PATH.exists():\n    shutil.copy2(prev_catalogue, CATALOGUE_PATH)\n    print(\"ğŸŸ¢ [IR Phase] Copied catalogue from previous run.\")\n\n# We MUST also copy the actual audio files if they exist, or Phase 6 will crash\nif prev_mit_irs.exists() and not any(MIT_IR_DIR.iterdir()):\n    print(\"ğŸŸ¢ [IR Phase] Copying MIT IR audio files from previous run...\")\n    shutil.copytree(prev_mit_irs, MIT_IR_DIR, dirs_exist_ok=True)\n\nif CATALOGUE_PATH.exists():\n    print(\"ğŸŸ¢ [IR Phase] Found existing catalogue. Bypassing extraction.\")\n    with open(CATALOGUE_PATH, 'r') as f:\n        ir_catalogue = json.load(f)\n        \n    for ir_id, feats in ir_catalogue.items():\n        if feats['source'] == 'mit':\n            target_pool.append(ir_id)\n        else:\n            bad_pool.append(ir_id)\n            \n    print(f\"ğŸŸ¢ [IR Phase] Re-hydrated pools -> Target (MIT): {len(target_pool)} | Bad (Custom): {len(bad_pool)}\")\n\nelse:\n    print(\"ğŸŸ¢ [IR Phase] Processing IRs from scratch...\")\n    \n    # Download and extract MIT IRs if the directory is empty\n    if not any(MIT_IR_DIR.iterdir()):\n        print(\"ğŸŸ¢ [IR Phase] Downloading MIT IRs...\")\n        zip_path = MIT_IR_DIR / 'mit_irs.zip'\n        urllib.request.urlretrieve(MIT_RAW_URL, str(zip_path))\n        with zipfile.ZipFile(zip_path, 'r') as zf:\n            zf.extractall(MIT_IR_DIR)\n        zip_path.unlink()\n        print(\"ğŸŸ¢ [IR Phase] MIT IRs downloaded and extracted.\")\n        \n    def process_ir(filepath: Path, source_tag: str):\n        try:\n            audio, _ = librosa.load(str(filepath), sr=SR, mono=True)\n            if len(audio) < 64: return\n            peak = np.max(np.abs(audio))\n            if peak > 1e-6: audio = audio / peak\n            \n            ir_id = f\"{source_tag}_{filepath.stem}\"\n            ir_catalogue[ir_id] = {'source': source_tag, 'path': str(filepath)}\n            \n            if source_tag == 'mit': target_pool.append(ir_id)\n            else: bad_pool.append(ir_id)\n        except Exception:\n            pass\n\n    # Process MIT (Target)\n    for f in MIT_IR_DIR.rglob('*.wav'):\n        process_ir(f, 'mit')\n        \n    # Process Custom (Bad)\n    for ext in ('*.irs', '*.wav'):\n        for f in PATHS['bad_irs'].rglob(ext):\n            process_ir(f, 'bad')\n\n    with open(CATALOGUE_PATH, 'w') as f:\n        json.dump(ir_catalogue, f, indent=2)\n        \n    print(f\"ğŸŸ¢ [IR Phase] Catalogue built -> Target: {len(target_pool)} | Bad: {len(bad_pool)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:39:33.613122Z","iopub.execute_input":"2026-02-26T03:39:33.613402Z","iopub.status.idle":"2026-02-26T03:39:35.486648Z","shell.execute_reply.started":"2026-02-26T03:39:33.613378Z","shell.execute_reply":"2026-02-26T03:39:35.485443Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [IR Phase] Processing IRs from scratch...\nğŸŸ¢ [IR Phase] Downloading MIT IRs...\nğŸŸ¢ [IR Phase] MIT IRs downloaded and extracted.\nğŸŸ¢ [IR Phase] Catalogue built -> Target: 270 | Bad: 389\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 3 â€” CLAP Target Embedding Cache\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCLAP_CACHE_PATH = OUTPUT / 'clap_cache.npz'\nprev_cache = PREV_RUN_PATH / 'clap_cache.npz'\nclap_cache_data = {}\n\n# â”€â”€â”€ Fast path: Load from cache â”€â”€â”€\nif prev_cache.exists() and not CLAP_CACHE_PATH.exists():\n    shutil.copy2(prev_cache, CLAP_CACHE_PATH)\n    print(\"ğŸŸ¢ [CLAP Phase] Copied embedding cache from previous run.\")\n\nif CLAP_CACHE_PATH.exists():\n    print(\"ğŸŸ¢ [CLAP Phase] Found existing clap_cache.npz. Bypassing model loading.\")\n    clap_cache_data = dict(np.load(CLAP_CACHE_PATH))\n    print(f\"ğŸŸ¢ [CLAP Phase] Loaded {len(clap_cache_data)} embeddings.\")\nelse:\n    print(\"ğŸŸ¢ [CLAP Phase] Loading model to compute embeddings...\")\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    CLAP_MODEL_ID = \"laion/larger_clap_music_and_speech\"\n    \n    # Handle frozen model transfer to avoid re-downloading\n    prev_clap_model = PREV_RUN_PATH / 'clap_model'\n    if prev_clap_model.exists() and not CLAP_DIR.exists():\n        shutil.copytree(prev_clap_model, CLAP_DIR, dirs_exist_ok=True)\n        \n    if (CLAP_DIR / 'config.json').exists():\n        clap_processor = ClapProcessor.from_pretrained(CLAP_DIR)\n        clap_model = ClapModel.from_pretrained(CLAP_DIR).to(device).eval()\n    else:\n        clap_processor = ClapProcessor.from_pretrained(CLAP_MODEL_ID)\n        clap_model = ClapModel.from_pretrained(CLAP_MODEL_ID).to(device).eval()\n        clap_model.save_pretrained(CLAP_DIR)\n        clap_processor.save_pretrained(CLAP_DIR)\n\n    ref_noise = np.random.randn(SR * 3).astype(np.float32) * 0.1\n    \n    for i, ir_id in enumerate(target_pool):\n        if ir_id not in ir_catalogue: continue\n        \n        ir_audio, _ = librosa.load(ir_catalogue[ir_id]['path'], sr=SR, mono=True)\n        scene = fftconvolve(ref_noise, ir_audio, mode='full')[:SR * 3]\n        scene = scene / (np.max(np.abs(scene)) + 1e-8)\n        \n        inputs = clap_processor(audio=scene, sampling_rate=SR, return_tensors=\"pt\")\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = clap_model.get_audio_features(**inputs)\n            # Critical: Must extract pooler_output\n            emb = outputs.pooler_output.cpu().numpy().flatten().astype(np.float32)\n            \n        clap_cache_data[ir_id] = emb\n        \n    np.savez(CLAP_CACHE_PATH, **clap_cache_data)\n    print(f\"ğŸŸ¢ [CLAP Phase] Computed and cached {len(clap_cache_data)} embeddings.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:39:35.488142Z","iopub.execute_input":"2026-02-26T03:39:35.488408Z","iopub.status.idle":"2026-02-26T03:42:30.958605Z","shell.execute_reply.started":"2026-02-26T03:39:35.488386Z","shell.execute_reply":"2026-02-26T03:42:30.957283Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [CLAP Phase] Loading model to compute embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/555 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9bf7cf391574a7bb6bebec2a67d3542"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9cb95648d514dcf9d3ead79ec16b4ae"}},"metadata":{}},{"name":"stdout","text":"ğŸŸ¢ [CLAP Phase] Computed and cached 270 embeddings.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PHASE 4 â€” Vocal Sterilization & \"Dead\" Audio Guarantee\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTATE_FILE = STERILIZED_DIR / 'sterilize_state.json'\nprev_sterilized = PREV_RUN_PATH / 'sterilized_batches'\n\n# â”€â”€â”€ Fast path: Transfer previous chunks â”€â”€â”€\nif prev_sterilized.exists() and (prev_sterilized / 'sterilize_state.json').exists():\n    if not STATE_FILE.exists():\n        shutil.copytree(prev_sterilized, STERILIZED_DIR, dirs_exist_ok=True)\n        print(\"ğŸŸ¢ [Sterilize Phase] Copied sterilized batches from previous run.\")\n\n_st = {}\nif STATE_FILE.exists():\n    with open(STATE_FILE) as f:\n        _st = json.load(f)\n\nif _st.get('completed', False):\n    print(\"ğŸŸ¢ [Sterilize Phase] Sterilization previously completed. Bypassing extraction.\")\nelse:\n    print(\"ğŸŸ¢ [Sterilize Phase] Discovering source audio...\")\n    meter = pyln.Meter(SR)\n    all_files = []\n    \n    for p in PATHS.values():\n        if p.name in ['impulse-responses', 'MIT_Reverb_Dataset']: continue\n        for ext in ('*.wav', '*.mp3', '*.ogg'):\n            all_files.extend([(f, p.name) for f in p.rglob(ext)])\n            \n    all_files.sort(key=lambda x: str(x[0]))\n    random.Random(42).shuffle(all_files)\n    print(f\"ğŸŸ¢ [Sterilize Phase] Found {len(all_files)} raw vocal files.\")\n    \n    cursor = _st.get('cursor', 0)\n    print(f\"ğŸŸ¢ [Sterilize Phase] Resuming extraction at file index: {cursor}\")\n    \n    vocal_segments = []\n    STERILIZE_CHUNK = 500\n    \n    for i in range(cursor, len(all_files)):\n        if get_output_size_gb() > MAX_OUTPUT_GB:\n            print(f\"âš ï¸ Output limit reached. Pausing sterilization.\")\n            break\n            \n        fpath, tag = all_files[i]\n        try:\n            audio, _ = librosa.load(str(fpath), sr=SR, mono=True)\n            if len(audio) < SR * 1.5: continue\n            \n            audio = nr.reduce_noise(y=audio, sr=SR, stationary=True, prop_decrease=0.85)\n            audio, _ = librosa.effects.trim(audio, top_db=40)\n            if len(audio) < SR * 1.5: continue\n            \n            loudness = meter.integrated_loudness(audio)\n            if loudness > -70: audio = pyln.normalize.loudness(audio, loudness, -23.0)\n            \n            for start in range(0, len(audio) - SR, CLIP_SAMPLES):\n                chunk = audio[start : start + CLIP_SAMPLES]\n                if len(chunk) < CLIP_SAMPLES:\n                    chunk = np.pad(chunk, (0, CLIP_SAMPLES - len(chunk)))\n                \n                if np.sqrt(np.mean(chunk ** 2)) < 1e-4: continue\n                vocal_segments.append({'audio': chunk.astype(np.float32), 'file': fpath.name, 'dataset': tag})\n                \n        except Exception: pass\n        \n        # Flush to disk to protect RAM\n        if (i + 1) % STERILIZE_CHUNK == 0 or (i + 1) == len(all_files):\n            batch_idx = (i + 1) // STERILIZE_CHUNK\n            batch_path = STERILIZED_DIR / f\"sterilized_batch_{batch_idx:04d}.pkl\"\n            with open(batch_path, 'wb') as f:\n                pickle.dump(vocal_segments, f)\n                \n            completed = (i + 1) >= len(all_files)\n            with open(STATE_FILE, 'w') as f:\n                json.dump({'cursor': i + 1, 'completed': completed}, f)\n                \n            print(f\"  ğŸ’¾ Saved {len(vocal_segments)} segments to {batch_path.name}. RAM cleared.\")\n            vocal_segments.clear()\n\n# Verification check\ntotal_segs = sum(len(pickle.load(open(f, 'rb'))) for f in STERILIZED_DIR.glob('*.pkl'))\nprint(f\"ğŸŸ¢ [Sterilize Phase] Total sterilized 5.0s segments on disk: {total_segs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:42:30.960478Z","iopub.execute_input":"2026-02-26T03:42:30.960957Z","iopub.status.idle":"2026-02-26T04:35:57.058402Z","shell.execute_reply.started":"2026-02-26T03:42:30.960925Z","shell.execute_reply":"2026-02-26T04:35:57.057238Z"}},"outputs":[{"name":"stdout","text":"ğŸŸ¢ [Sterilize Phase] Discovering source audio...\nğŸŸ¢ [Sterilize Phase] Found 70442 raw vocal files.\nğŸŸ¢ [Sterilize Phase] Resuming extraction at file index: 0\n  ğŸ’¾ Saved 564 segments to sterilized_batch_0001.pkl. RAM cleared.\n  ğŸ’¾ Saved 1103 segments to sterilized_batch_0003.pkl. RAM cleared.\n  ğŸ’¾ Saved 535 segments to sterilized_batch_0004.pkl. RAM cleared.\n  ğŸ’¾ Saved 531 segments to sterilized_batch_0005.pkl. RAM cleared.\n  ğŸ’¾ Saved 535 segments to sterilized_batch_0006.pkl. RAM cleared.\n  ğŸ’¾ Saved 550 segments to sterilized_batch_0007.pkl. RAM cleared.\n  ğŸ’¾ Saved 545 segments to sterilized_batch_0008.pkl. RAM cleared.\n  ğŸ’¾ Saved 1068 segments to sterilized_batch_0010.pkl. RAM cleared.\n  ğŸ’¾ Saved 532 segments to sterilized_batch_0011.pkl. RAM cleared.\n  ğŸ’¾ Saved 556 segments to sterilized_batch_0012.pkl. RAM cleared.\n  ğŸ’¾ Saved 549 segments to sterilized_batch_0013.pkl. RAM cleared.\n  ğŸ’¾ Saved 542 segments to sterilized_batch_0014.pkl. RAM cleared.\n  ğŸ’¾ Saved 541 segments to sterilized_batch_0015.pkl. RAM cleared.\n  ğŸ’¾ Saved 546 segments to sterilized_batch_0016.pkl. RAM cleared.\n  ğŸ’¾ Saved 544 segments to sterilized_batch_0017.pkl. RAM cleared.\n  ğŸ’¾ Saved 517 segments to sterilized_batch_0018.pkl. RAM cleared.\n  ğŸ’¾ Saved 552 segments to sterilized_batch_0019.pkl. RAM cleared.\n  ğŸ’¾ Saved 542 segments to sterilized_batch_0020.pkl. RAM cleared.\n  ğŸ’¾ Saved 535 segments to sterilized_batch_0021.pkl. RAM cleared.\n  ğŸ’¾ Saved 540 segments to sterilized_batch_0022.pkl. RAM cleared.\n  ğŸ’¾ Saved 551 segments to sterilized_batch_0023.pkl. RAM cleared.\n  ğŸ’¾ Saved 551 segments to sterilized_batch_0024.pkl. RAM cleared.\n  ğŸ’¾ Saved 552 segments to sterilized_batch_0025.pkl. RAM cleared.\n  ğŸ’¾ Saved 545 segments to sterilized_batch_0026.pkl. RAM cleared.\n  ğŸ’¾ Saved 526 segments to sterilized_batch_0027.pkl. RAM cleared.\n  ğŸ’¾ Saved 522 segments to sterilized_batch_0028.pkl. RAM cleared.\n  ğŸ’¾ Saved 524 segments to sterilized_batch_0029.pkl. RAM cleared.\n  ğŸ’¾ Saved 549 segments to sterilized_batch_0030.pkl. RAM cleared.\n  ğŸ’¾ Saved 557 segments to sterilized_batch_0031.pkl. RAM cleared.\n  ğŸ’¾ Saved 1096 segments to sterilized_batch_0033.pkl. RAM cleared.\n  ğŸ’¾ Saved 558 segments to sterilized_batch_0034.pkl. RAM cleared.\n  ğŸ’¾ Saved 561 segments to sterilized_batch_0035.pkl. RAM cleared.\n  ğŸ’¾ Saved 1082 segments to sterilized_batch_0037.pkl. RAM cleared.\n  ğŸ’¾ Saved 526 segments to sterilized_batch_0038.pkl. RAM cleared.\nâš ï¸ Output limit reached. Pausing sterilization.\nğŸŸ¢ [Sterilize Phase] Total sterilized 5.0s segments on disk: 20627\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"---\n> âš ï¸ **Phase Skip**: Phases 2â€“4 above can be skipped entirely if a previous run\n> completed them successfully. The notebook detects existing `ir_catalogue.json`,\n> `clap_cache.npz`, and `sterilize_state.json` to bypass redundant computation.\n> Previous run files are located at `/kaggle/input/notebooks/itorousa/genesis-data-run#`.\n---\n","metadata":{}},{"cell_type":"markdown","source":"## ğŸ”— Checkpoint Chaining (20 GB Limit)\n\nIf the output hit the size limit before processing all vocals:\n\n1. **Save this notebook's output** as a Kaggle dataset (e.g. `genesis-data-run1`)\n2. **Create a new notebook** (with the full seven-phase code) and attach:\n   - All the same input datasets (IRs, LJSpeech, VCTK, Language Identifier)\n   - The previous output as input (update `PREV_RUN_PATH` in Cell 3)\n3. **Run all cells** â€” the checkpoint system automatically skips completed work\n\nEach run produces ~19 GB of training triples. Chain as many times as needed.\n\n### Using the Data in Training\n\n```python\n# In the training notebook, load all batches from all runs:\nimport numpy as np\nfrom pathlib import Path\n\nrun_dirs = [\n    Path('/kaggle/input/genesis-data-run1/batches'),\n    Path('/kaggle/input/genesis-data-run2/batches'),\n    # ... add more runs\n]\n\nfor run_dir in run_dirs:\n    for batch_file in sorted(run_dir.glob('batch_*.npz')):\n        data = np.load(batch_file)\n        source_audio = data['source_audio']   # (N, 240000) int16\n        target_audio = data['target_audio']   # (N, 240000) int16\n        target_clap  = data['target_clap']    # (N, CLAP_DIM) float32\n        # Convert int16 back to float32: audio = source_audio.astype(np.float32) / 32767\n        # Compute STFT on-the-fly during training for memory efficiency\n```\n","metadata":{}}]}