{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14927063,"datasetId":9551535,"databundleVersionId":15794187},{"sourceType":"datasetVersion","sourceId":101413,"datasetId":53291,"databundleVersionId":103953},{"sourceType":"datasetVersion","sourceId":4588404,"datasetId":2675000,"databundleVersionId":4649793}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q noisereduce pyloudnorm soundfile librosa transformers torch\n\nimport os, json, hashlib, time, random, warnings, shutil, pickle\nfrom pathlib import Path\nfrom typing import Optional, List, Dict, Tuple\nfrom collections import defaultdict\n\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom scipy.signal import fftconvolve\nimport noisereduce as nr\nimport torch\nfrom transformers import ClapModel, ClapProcessor\nimport pyloudnorm as pyln\n\nwarnings.filterwarnings('ignore')\nrandom.seed(42)\nnp.random.seed(42)\n\nprint(\"üü¢ [Setup] Libraries imported and deterministic seeds set.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:37:10.566370Z","iopub.execute_input":"2026-02-25T06:37:10.566789Z","iopub.status.idle":"2026-02-25T06:37:16.487488Z","shell.execute_reply.started":"2026-02-25T06:37:10.566755Z","shell.execute_reply":"2026-02-25T06:37:16.486186Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Wipe Kaggle's Output Storage","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\nworking_dir = '/kaggle/working'\n\nprint(\"üü° Wiping Kaggle working directory...\")\n\nfor item in os.listdir(working_dir):\n    item_path = os.path.join(working_dir, item)\n    try:\n        if os.path.isfile(item_path) or os.path.islink(item_path):\n            os.unlink(item_path)\n        elif os.path.isdir(item_path):\n            shutil.rmtree(item_path)\n    except Exception as e:\n        print(f\"üî¥ Failed to delete {item_path}. Reason: {e}\")\n\nprint(\"üü¢ Kaggle working directory is completely clean.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:37:26.045813Z","iopub.execute_input":"2026-02-25T06:37:26.047038Z","iopub.status.idle":"2026-02-25T06:37:26.056482Z","shell.execute_reply.started":"2026-02-25T06:37:26.046988Z","shell.execute_reply":"2026-02-25T06:37:26.055338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Wipe a Specific Folder/File","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\ndef delete_target(target_path):\n    target = Path(target_path)\n    \n    if not target.exists():\n        print(f\"üü° Target does not exist: {target}\")\n        return\n        \n    try:\n        if target.is_file() or target.is_symlink():\n            target.unlink()\n            print(f\"üü¢ Successfully deleted file: {target}\")\n        elif target.is_dir():\n            shutil.rmtree(target)\n            print(f\"üü¢ Successfully deleted directory: {target}\")\n    except Exception as e:\n        print(f\"üî¥ Failed to delete {target}. Reason: {e}\")\n\n# Just drop your path here\ndelete_target('/kaggle/working/your_folder_or_file_here')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n# PHASE 0 ‚Äî Environment & Path Configuration\n# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n# KAGGLE INPUT PATHS\nPATHS = {\n    'bad_irs':   Path('/kaggle/input/datasets/itorousa/impulse-responses'),\n    'mit_irs':   Path('/kaggle/input/datasets/kynthesis/mit-reverb-dataset/MIT_Reverb_Dataset/MIT_Reverb_Dataset'),\n    'ljspeech':  Path('/kaggle/input/datasets/dromosys/ljspeech/'),\n    'vctk':      Path('/kaggle/input/datasets/kynthesis/vctk-corpus/VCTK-Corpus/wav48'),\n#   'langid_en': Path('/kaggle/input/datasets/shrivatssudhir/language-identifier/english/clips')\n}\n\n# ‚ö†Ô∏è UPDATE THIS PATH WHEN CHAINING RUNS ‚ö†Ô∏è\nPREV_RUN_PATH = Path('/kaggle/input/notebooks/itorousa/genesis-data-run1')\n\n# OUTPUT PATHS\nOUTPUT          = Path('/kaggle/working')\nBATCH_DIR       = OUTPUT / 'batches'\nCLAP_DIR        = OUTPUT / 'clap_model'\nSTERILIZED_DIR  = OUTPUT / 'sterilized_batches'\nMIT_IR_DIR      = OUTPUT / 'irs' / 'mit_irs'\n\nfor d in [BATCH_DIR, CLAP_DIR, STERILIZED_DIR, MIT_IR_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n\n# AUDIO PARAMETERS & BUDGET\nSR            = 48_000\nCLIP_SEC      = 5.0\nCLIP_SAMPLES  = int(SR * CLIP_SEC)\nTRIPLES_PER_BATCH  = 500\nMAX_OUTPUT_GB      = 19.0 \n\nprint(f\"üü¢ [Config] Output budget: {MAX_OUTPUT_GB} GB | SR: {SR} | Batch Size: {TRIPLES_PER_BATCH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:37:32.566306Z","iopub.execute_input":"2026-02-25T06:37:32.566612Z","iopub.status.idle":"2026-02-25T06:37:37.158256Z","shell.execute_reply.started":"2026-02-25T06:37:32.566587Z","shell.execute_reply":"2026-02-25T06:37:37.157185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n# PHASE 1 ‚Äî Aggressive Checkpoint Initialization\n# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nCHECKPOINT_PATH = OUTPUT / 'checkpoint.json'\n\ndef get_output_size_gb() -> float:\n    '''Calculate the exact size of /kaggle/working in GB.'''\n    total = sum(f.stat().st_size for f in OUTPUT.rglob('*') if f.is_file())\n    return total / (1024 ** 3)\n\ndef load_checkpoint() -> dict:\n    # 1) Check previous run first (chaining)\n    prev_ckpt = PREV_RUN_PATH / 'checkpoint.json'\n    if prev_ckpt.exists():\n        with open(prev_ckpt) as f:\n            ckpt = json.load(f)\n        ckpt['run_number'] += 1\n        print(f\"üü¢ [Checkpoint] ‚ôª Resuming from previous run: {ckpt['triples_completed']} triples done\")\n        return ckpt\n\n    # 2) Check current working dir (kernel restart mid-session)\n    if CHECKPOINT_PATH.exists():\n        with open(CHECKPOINT_PATH) as f:\n            return json.load(f)\n\n    # 3) Fresh start\n    return {\n        'batch_id': 0,\n        'triples_completed': 0,\n        'vocal_cursor': 0,\n        'run_number': 1,\n    }\n\ndef save_checkpoint(ckpt: dict):\n    with open(CHECKPOINT_PATH, 'w') as f:\n        json.dump(ckpt, f, indent=2)\n\nckpt = load_checkpoint()\nsave_checkpoint(ckpt) # Initialize immediately\n\nprint(f\"üü¢ [Checkpoint] Run #{ckpt['run_number']} | Starting at vocal cursor {ckpt['vocal_cursor']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:39:49.815676Z","iopub.execute_input":"2026-02-25T06:39:49.816269Z","iopub.status.idle":"2026-02-25T06:39:49.828429Z","shell.execute_reply.started":"2026-02-25T06:39:49.816239Z","shell.execute_reply":"2026-02-25T06:39:49.827267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n# PHASE 2 ‚Äî Impulse Response Acquisition & Pooling\n# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nCATALOGUE_PATH = OUTPUT / 'ir_catalogue.json'\nprev_catalogue = PREV_RUN_PATH / 'ir_catalogue.json'\n\nbad_pool: List[str] = []\ntarget_pool: List[str] = []\nir_catalogue: Dict = {}\n\n# ‚îÄ‚îÄ‚îÄ Fast path: Copy from previous run if exists ‚îÄ‚îÄ‚îÄ\nif prev_catalogue.exists() and not CATALOGUE_PATH.exists():\n    shutil.copy2(prev_catalogue, CATALOGUE_PATH)\n    print(\"üü¢ [IR Phase] Copied catalogue from previous run.\")\n\nif CATALOGUE_PATH.exists():\n    print(\"üü¢ [IR Phase] Found existing catalogue. Bypassing extraction.\")\n    with open(CATALOGUE_PATH, 'r') as f:\n        ir_catalogue = json.load(f)\n        \n    for ir_id, feats in ir_catalogue.items():\n        if feats['source'] == 'mit':\n            target_pool.append(ir_id)\n        else:\n            bad_pool.append(ir_id)\n            \n    print(f\"üü¢ [IR Phase] Re-hydrated pools -> Target (MIT): {len(target_pool)} | Bad (Custom): {len(bad_pool)}\")\n\nelse:\n    print(\"üü¢ [IR Phase] Processing IRs from scratch...\")\n    \n    # Copy MIT IRs to working directory for easier access later\n    if PATHS['mit_irs'].exists():\n        shutil.copytree(PATHS['mit_irs'], MIT_IR_DIR, dirs_exist_ok=True)\n        \n    def process_ir(filepath: Path, source_tag: str):\n        try:\n            audio, _ = librosa.load(str(filepath), sr=SR, mono=True)\n            if len(audio) < 64: return\n            peak = np.max(np.abs(audio))\n            if peak > 1e-6: audio = audio / peak\n            \n            ir_id = f\"{source_tag}_{filepath.stem}\"\n            ir_catalogue[ir_id] = {'source': source_tag, 'path': str(filepath)}\n            \n            if source_tag == 'mit': target_pool.append(ir_id)\n            else: bad_pool.append(ir_id)\n        except Exception:\n            pass\n\n    # Process MIT (Target)\n    for f in MIT_IR_DIR.rglob('*.wav'):\n        process_ir(f, 'mit')\n        \n    # Process Custom (Bad)\n    for ext in ('*.irs', '*.wav'):\n        for f in PATHS['bad_irs'].rglob(ext):\n            process_ir(f, 'bad')\n\n    with open(CATALOGUE_PATH, 'w') as f:\n        json.dump(ir_catalogue, f, indent=2)\n        \n    print(f\"üü¢ [IR Phase] Catalogue built -> Target: {len(target_pool)} | Bad: {len(bad_pool)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:40:01.316951Z","iopub.execute_input":"2026-02-25T06:40:01.317839Z","iopub.status.idle":"2026-02-25T06:40:36.132614Z","shell.execute_reply.started":"2026-02-25T06:40:01.317806Z","shell.execute_reply":"2026-02-25T06:40:36.130987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n# PHASE 3 ‚Äî CLAP Target Embedding Cache\n# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nCLAP_CACHE_PATH = OUTPUT / 'clap_cache.npz'\nprev_cache = PREV_RUN_PATH / 'clap_cache.npz'\nclap_cache_data = {}\n\n# ‚îÄ‚îÄ‚îÄ Fast path: Load from cache ‚îÄ‚îÄ‚îÄ\nif prev_cache.exists() and not CLAP_CACHE_PATH.exists():\n    shutil.copy2(prev_cache, CLAP_CACHE_PATH)\n    print(\"üü¢ [CLAP Phase] Copied embedding cache from previous run.\")\n\nif CLAP_CACHE_PATH.exists():\n    print(\"üü¢ [CLAP Phase] Found existing clap_cache.npz. Bypassing model loading.\")\n    clap_cache_data = dict(np.load(CLAP_CACHE_PATH))\n    print(f\"üü¢ [CLAP Phase] Loaded {len(clap_cache_data)} embeddings.\")\nelse:\n    print(\"üü¢ [CLAP Phase] Loading model to compute embeddings...\")\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    CLAP_MODEL_ID = \"laion/larger_clap_music_and_speech\"\n    \n    # Handle frozen model transfer to avoid re-downloading\n    prev_clap_model = PREV_RUN_PATH / 'clap_model'\n    if prev_clap_model.exists() and not CLAP_DIR.exists():\n        shutil.copytree(prev_clap_model, CLAP_DIR, dirs_exist_ok=True)\n        \n    if (CLAP_DIR / 'config.json').exists():\n        clap_processor = ClapProcessor.from_pretrained(CLAP_DIR)\n        clap_model = ClapModel.from_pretrained(CLAP_DIR).to(device).eval()\n    else:\n        clap_processor = ClapProcessor.from_pretrained(CLAP_MODEL_ID)\n        clap_model = ClapModel.from_pretrained(CLAP_MODEL_ID).to(device).eval()\n        clap_model.save_pretrained(CLAP_DIR)\n        clap_processor.save_pretrained(CLAP_DIR)\n\n    ref_noise = np.random.randn(SR * 3).astype(np.float32) * 0.1\n    \n    for i, ir_id in enumerate(target_pool):\n        if ir_id not in ir_catalogue: continue\n        \n        ir_audio, _ = librosa.load(ir_catalogue[ir_id]['path'], sr=SR, mono=True)\n        scene = fftconvolve(ref_noise, ir_audio, mode='full')[:SR * 3]\n        scene = scene / (np.max(np.abs(scene)) + 1e-8)\n        \n        inputs = clap_processor(audio=scene, sampling_rate=SR, return_tensors=\"pt\")\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = clap_model.get_audio_features(**inputs)\n            # Critical: Must extract pooler_output\n            emb = outputs.pooler_output.cpu().numpy().flatten().astype(np.float32)\n            \n        clap_cache_data[ir_id] = emb\n        \n    np.savez(CLAP_CACHE_PATH, **clap_cache_data)\n    print(f\"üü¢ [CLAP Phase] Computed and cached {len(clap_cache_data)} embeddings.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:42:20.797720Z","iopub.execute_input":"2026-02-25T06:42:20.798080Z","iopub.status.idle":"2026-02-25T06:46:41.192289Z","shell.execute_reply.started":"2026-02-25T06:42:20.798037Z","shell.execute_reply":"2026-02-25T06:46:41.191035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n# PHASE 4 ‚Äî Vocal Sterilization & \"Dead\" Audio Guarantee\n# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nSTATE_FILE = STERILIZED_DIR / 'sterilize_state.json'\nprev_sterilized = PREV_RUN_PATH / 'sterilized_batches'\n\n# ‚îÄ‚îÄ‚îÄ Fast path: Transfer previous chunks ‚îÄ‚îÄ‚îÄ\nif prev_sterilized.exists() and (prev_sterilized / 'sterilize_state.json').exists():\n    if not STATE_FILE.exists():\n        shutil.copytree(prev_sterilized, STERILIZED_DIR, dirs_exist_ok=True)\n        print(\"üü¢ [Sterilize Phase] Copied sterilized batches from previous run.\")\n\n_st = {}\nif STATE_FILE.exists():\n    with open(STATE_FILE) as f:\n        _st = json.load(f)\n\nif _st.get('completed', False):\n    print(\"üü¢ [Sterilize Phase] Sterilization previously completed. Bypassing extraction.\")\nelse:\n    print(\"üü¢ [Sterilize Phase] Discovering source audio...\")\n    meter = pyln.Meter(SR)\n    all_files = []\n    \n    for p in PATHS.values():\n        if p.name in ['impulse-responses', 'MIT_Reverb_Dataset']: continue\n        for ext in ('*.wav', '*.mp3', '*.ogg'):\n            all_files.extend([(f, p.name) for f in p.rglob(ext)])\n            \n    all_files.sort(key=lambda x: str(x[0]))\n    random.Random(42).shuffle(all_files)\n    print(f\"üü¢ [Sterilize Phase] Found {len(all_files)} raw vocal files.\")\n    \n    cursor = _st.get('cursor', 0)\n    print(f\"üü¢ [Sterilize Phase] Resuming extraction at file index: {cursor}\")\n    \n    vocal_segments = []\n    STERILIZE_CHUNK = 500\n    \n    for i in range(cursor, len(all_files)):\n        if get_output_size_gb() > MAX_OUTPUT_GB:\n            print(f\"‚ö†Ô∏è Output limit reached. Pausing sterilization.\")\n            break\n            \n        fpath, tag = all_files[i]\n        try:\n            audio, _ = librosa.load(str(fpath), sr=SR, mono=True)\n            if len(audio) < SR * 1.5: continue\n            \n            audio = nr.reduce_noise(y=audio, sr=SR, stationary=True, prop_decrease=0.85)\n            audio, _ = librosa.effects.trim(audio, top_db=40)\n            if len(audio) < SR * 1.5: continue\n            \n            loudness = meter.integrated_loudness(audio)\n            if loudness > -70: audio = pyln.normalize.loudness(audio, loudness, -23.0)\n            \n            for start in range(0, len(audio) - SR, CLIP_SAMPLES):\n                chunk = audio[start : start + CLIP_SAMPLES]\n                if len(chunk) < CLIP_SAMPLES:\n                    chunk = np.pad(chunk, (0, CLIP_SAMPLES - len(chunk)))\n                \n                if np.sqrt(np.mean(chunk ** 2)) < 1e-4: continue\n                vocal_segments.append({'audio': chunk.astype(np.float32), 'file': fpath.name, 'dataset': tag})\n                \n        except Exception: pass\n        \n        # Flush to disk to protect RAM\n        if (i + 1) % STERILIZE_CHUNK == 0 or (i + 1) == len(all_files):\n            batch_idx = (i + 1) // STERILIZE_CHUNK\n            batch_path = STERILIZED_DIR / f\"sterilized_batch_{batch_idx:04d}.pkl\"\n            with open(batch_path, 'wb') as f:\n                pickle.dump(vocal_segments, f)\n                \n            completed = (i + 1) >= len(all_files)\n            with open(STATE_FILE, 'w') as f:\n                json.dump({'cursor': i + 1, 'completed': completed}, f)\n                \n            print(f\"  üíæ Saved {len(vocal_segments)} segments to {batch_path.name}. RAM cleared.\")\n            vocal_segments.clear()\n\n# Verification check\ntotal_segs = sum(len(pickle.load(open(f, 'rb'))) for f in STERILIZED_DIR.glob('*.pkl'))\nprint(f\"üü¢ [Sterilize Phase] Total sterilized 5.0s segments on disk: {total_segs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:47:46.807364Z","iopub.execute_input":"2026-02-25T06:47:46.808263Z","iopub.status.idle":"2026-02-25T07:47:32.007877Z","shell.execute_reply.started":"2026-02-25T06:47:46.808226Z","shell.execute_reply":"2026-02-25T07:47:32.003402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n> ‚ö†Ô∏è **Phase Skip**: Phases 2‚Äì4 above can be skipped entirely if a previous run\n> completed them successfully. The notebook detects existing `ir_catalogue.json`,\n> `clap_cache.npz`, and `sterilize_state.json` to bypass redundant computation.\n> Previous run files are located at `/kaggle/input/notebooks/itorousa/genesis-data-run#`.\n---\n","metadata":{}},{"cell_type":"markdown","source":"## üîó Checkpoint Chaining (20 GB Limit)\n\nIf the output hit the size limit before processing all vocals:\n\n1. **Save this notebook's output** as a Kaggle dataset (e.g. `genesis-data-run1`)\n2. **Create a new notebook** (with the full seven-phase code) and attach:\n   - All the same input datasets (IRs, LJSpeech, VCTK, Language Identifier)\n   - The previous output as input (update `PREV_RUN_PATH` in Cell 3)\n3. **Run all cells** ‚Äî the checkpoint system automatically skips completed work\n\nEach run produces ~19 GB of training triples. Chain as many times as needed.\n\n### Using the Data in Training\n\n```python\n# In the training notebook, load all batches from all runs:\nimport numpy as np\nfrom pathlib import Path\n\nrun_dirs = [\n    Path('/kaggle/input/genesis-data-run1/batches'),\n    Path('/kaggle/input/genesis-data-run2/batches'),\n    # ... add more runs\n]\n\nfor run_dir in run_dirs:\n    for batch_file in sorted(run_dir.glob('batch_*.npz')):\n        data = np.load(batch_file)\n        source_audio = data['source_audio']   # (N, 240000) int16\n        target_audio = data['target_audio']   # (N, 240000) int16\n        target_clap  = data['target_clap']    # (N, CLAP_DIM) float32\n        # Convert int16 back to float32: audio = source_audio.astype(np.float32) / 32767\n        # Compute STFT on-the-fly during training for memory efficiency\n```\n","metadata":{}}]}